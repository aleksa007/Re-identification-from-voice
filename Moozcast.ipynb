{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ca0801c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae7acdba",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22cbded7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch v1.8.1+cu111\n",
      "CUDA device available: True\n",
      "1 devices available\n",
      "\tNVIDIA GeForce RTX 2080 SUPER\n",
      "cuda: 0\n",
      "Num threads set to: 48\n",
      "device= cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(os.cpu_count())\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = str(os.cpu_count())\n",
    "os.environ[\"MKL_NUM_THREADS\"] = str(os.cpu_count())\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = str(os.cpu_count())\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = str(os.cpu_count())\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import dill as dill\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import imageio\n",
    "import inspect\n",
    "import json\n",
    "import numpy as np\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext.data as ttd\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools #Needed fot Confusion Matrix\n",
    "import scipy.stats as stat # Since the p-values are obtained through certain statistics, we need the 'stat' module from scipy.stats\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cmap #Importing colormap\n",
    "sns.set()\n",
    "\n",
    "from pytz import timezone\n",
    "from datetime import datetime\n",
    "from sklearn import linear_model\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import f_regression #Gets the p-values of the coefficients\n",
    "from sklearn.cluster import KMeans\n",
    "from torchsummary import summary\n",
    "from torchtext.vocab import GloVe\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets, transforms, models\n",
    "from skimage.io import imread\n",
    "from winsound import Beep\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "print(\"PyTorch v\" + torch.__version__)\n",
    "IS_GPU_AVAILABLE = torch.cuda.is_available()\n",
    "print(f\"CUDA device available: {IS_GPU_AVAILABLE}\")\n",
    "if (torch.cuda.is_available()):\n",
    "    print(str(torch.cuda.device_count()) + \" devices available\")\n",
    "    for n in range(torch.cuda.device_count()):\n",
    "        print(\"\\t\" + torch.cuda.get_device_name(n))\n",
    "    print(\"cuda:\", torch.cuda.current_device()) #It can give you information like the GPU is not supported\n",
    "print(\"Num threads set to:\", os.cpu_count())\n",
    "torch.set_num_threads(os.cpu_count())\n",
    "\n",
    "def SaveVariable(Variable, FileName):\n",
    "    with open(FileName, 'wb') as io:\n",
    "        pickle.dump(Variable, io)\n",
    "    \n",
    "def LoadVariable(FileName):\n",
    "    with open(FileName, \"rb\") as io:\n",
    "        Res = pickle.load(io)\n",
    "    return Res\n",
    "\n",
    "def RemLastLine(s):\n",
    "    return s[:s.rfind('\\n')]\n",
    "\n",
    "def init_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize = False, title = 'Confusion matrix', cmap = plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalisation can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalisation')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation = 45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment = \"center\",\n",
    "                 color = \"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "print(\"device=\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db07d9a7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69e190e6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NxD_to_NxTxD2_From_D_Dataset(Dataset): #Here, the previous steps are not previous observations (on N), but are within the D dimension on an NxD Matrix\n",
    "    def __init__(self, data, targets, T):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.shape = (data.shape[0], T, data.shape[1] - T)\n",
    "        self.T = T\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        NewX = []\n",
    "        for t in range(self.data.shape[1] - self.T):\n",
    "            x = self.data[index, t : t + self.T]\n",
    "            NewX.append(x)\n",
    "        \n",
    "        NewX = np.array(NewX).reshape(-1, self.shape[1], self.shape[2])\n",
    "        NewX = np.transpose(NewX, (1, 2, 0))\n",
    "        Targets = self.targets[index]\n",
    "\n",
    "        return NewX, Targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __shape__(self):\n",
    "        return self.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92458f0c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values: Y (600), Y_Train (600), Y_Test (600), all values are the same: True\n",
      "\n",
      "Y_Test[:10]: [362 557  25  25 145 386 587 541 108 475]\n",
      "\n",
      "X.shape       (9600, 11025) Y.shape       (9600,)\n",
      "X_Train.shape (6719, 11025)  Y_Train.shape (6719,)\n",
      "X_Test.shape  (2881, 11025)  Y_Test.shape  (2881,)\n",
      "K          600\n",
      "N: 6719 H1: 0 W1: 0 D: 11025\n"
     ]
    }
   ],
   "source": [
    "SupervisedType = \"Classification\"\n",
    "UsingPretrainedModel = False\n",
    "CustomNAString = None\n",
    "nEmbeddings = None\n",
    "CustomNAString = None\n",
    "RandomState = 1337\n",
    "T = 10500\n",
    "\n",
    "#################\n",
    "### One File ###\n",
    "X, Y = LoadVariable(f\"{os.getcwd()}/raw_data.pkl\")\n",
    "#################\n",
    "\n",
    "\n",
    "XY = pd.DataFrame(X)\n",
    "XY[\"Label\"] = Y\n",
    "XY[\"Label\"] = XY[\"Label\"].astype('category').cat.codes\n",
    "Y = XY[\"Label\"].values\n",
    "\n",
    "N = X.shape[0]\n",
    "\n",
    "init_seeds(1337)\n",
    "TrainPerc = 0.7\n",
    "TrainIndx, TestIndx = train_test_split(np.arange(X.shape[0]), test_size = 1 - TrainPerc, shuffle = True, stratify = Y, random_state = RandomState)\n",
    "X_Train = X[TrainIndx]\n",
    "Y_Train = Y[TrainIndx]\n",
    "X_Test = X[TestIndx]\n",
    "Y_Test = Y[TestIndx]\n",
    "\n",
    "YUnique = set(Y)\n",
    "Y_TrainUnique = set(Y_Train)\n",
    "Y_TestUnique = set(Y_Test)\n",
    "print(f\"Unique Values: Y ({len(YUnique)}), Y_Train ({len(Y_TrainUnique)}), Y_Test ({len(Y_TestUnique)}), all values are the same: {YUnique == Y_TrainUnique == Y_TestUnique}\")\n",
    "\n",
    "\n",
    "# print(\"\\n      X:\", type(X), X.shape, X.min(), X.max())\n",
    "# print(\"X_Train:\", type(X_Train), X_Train.shape, X_Train.min(), X_Train.max())\n",
    "# print(\"X_Test :\", type(X_Test), X_Test.shape, X_Test.min(), X_Test.max())\n",
    "\n",
    "# print(\"\\nY:      \", type(Y), Y.shape, min(Y), max(Y), len(set(Y)))\n",
    "# print(\"Y_Train:\", type(Y_Train), Y_Train.shape, min(Y_Train), max(Y_Train), len(set(Y_Train)))\n",
    "# print(\"Y_Test: \", type(Y_Test), Y_Test.shape, min(Y_Test), max(Y_Test), len(set(Y_Test)))\n",
    "# return\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "# train_dataset = NxD_to_NxTxD2_From_D_Dataset(X_Train, Y_Train, T)\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     dataset = train_dataset, \n",
    "#     batch_size = batch_size, \n",
    "#     shuffle = True\n",
    "# )\n",
    "\n",
    "# test_dataset = NxD_to_NxTxD2_From_D_Dataset(X_Test, Y_Test, T)\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     dataset = test_dataset, \n",
    "#     batch_size = batch_size, \n",
    "#     shuffle = True\n",
    "# )\n",
    "\n",
    "print(\"\\nY_Test[:10]:\", Y_Test[:10])\n",
    "\n",
    "# number of classes\n",
    "K = len(set(Y)) if SupervisedType.lower() == \"classification\" and len(set(Y)) != 2 else (Y.shape[1] if SupervisedType.lower() == \"multivariateregression\" else 1) #An output_size (K) > 1 can be either Multiclass or Multivariate-Regression, like Lat/Lon coordinates\n",
    "\n",
    "if 'train_dataset' in locals() or 'train_dataset' in globals():\n",
    "    tmpX, tmpY = next(iter(train_loader))\n",
    "    NonSingularDims = np.sum([1 for DimVal in tmpX.shape if DimVal > 1])\n",
    "    if NonSingularDims == 2:\n",
    "        N, D = [DimVal for DimVal in tmpX.shape if DimVal > 1]\n",
    "        H1, W1 = (0, 0)\n",
    "    elif NonSingularDims == 3:\n",
    "        D = 0\n",
    "        N, H1, W1 =[DimVal for DimVal in tmpX.shape if DimVal > 1] #This is RNN NxTxD\n",
    "    elif NonSingularDims == 4:\n",
    "        N, H1, W1, D = [DimVal for DimVal in tmpX.shape if DimVal > 1]\n",
    "    \n",
    "else:\n",
    "    if len(X_Train.shape) == 2:\n",
    "        N, D = X_Train.shape\n",
    "        H1, W1 = (0, 0)\n",
    "    elif len(X_Train.shape) == 3:\n",
    "        D = 0\n",
    "        N, H1, W1 = X_Train.shape #This is a Picture with no Colour, not RNN\n",
    "    elif len(X_Train.shape) == 4:\n",
    "        N, H1, W1, D = X_Train.shape\n",
    "\n",
    "print()\n",
    "print(\"X.shape      \", X.shape, \"Y.shape      \", Y.shape)\n",
    "print(\"X_Train.shape\", X_Train.shape, \" Y_Train.shape\", Y_Train.shape)\n",
    "print(\"X_Test.shape \", X_Test.shape, \" Y_Test.shape \", Y_Test.shape)\n",
    "print(\"K         \", K)\n",
    "print(\"N:\", N, \"H1:\", H1, \"W1:\", W1, \"D:\", D)\n",
    "if 'train_dataset' in locals() or 'train_dataset' in globals():\n",
    "    print(f\"\\nData after transformation with batch size = {batch_size}:\")\n",
    "    print(\"X.shape\", tuple(tmpX.shape), \"\\tY.shape\", tuple(tmpY.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9786be44",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84960f72",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db73ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Static\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, K, nEmbeddings):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features=11025, out_features=6000, bias=False),\n",
    "            nn.ReLU6(),\n",
    "            nn.BatchNorm1d(6000, eps=1e-05, momentum=0.7, affine=True, track_running_stats=True),\n",
    "            nn.Linear(in_features=6000, out_features=6000, bias=False),\n",
    "            nn.ReLU6(),\n",
    "            nn.BatchNorm1d(6000, eps=1e-05, momentum=0.7, affine=True, track_running_stats=True),\n",
    "            nn.Linear(in_features=6000, out_features=6000, bias=False),\n",
    "            nn.ReLU6(),\n",
    "            nn.BatchNorm1d(6000, eps=1e-05, momentum=0.7, affine=True, track_running_stats=True),\n",
    "            nn.Linear(in_features=6000, out_features=6000, bias=False),\n",
    "            nn.ReLU6(),\n",
    "            nn.BatchNorm1d(6000, eps=1e-05, momentum=0.7, affine=True, track_running_stats=True),\n",
    "            nn.Linear(in_features=6000, out_features=600, bias=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.layers(X)\n",
    "        return out\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13062c88",
   "metadata": {},
   "source": [
    "## Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9c9701a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_input_size: (11025,), input_size: 11025, D: 11025, output_size: 600\n",
      "doFlatten= False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if 'train_dataset' in locals() or 'train_dataset' in globals():\n",
    "    conv_input_size = tuple([DimVal for DimVal in tmpX[0].shape if DimVal > 1])\n",
    "else:\n",
    "    conv_input_size = X[0].shape #Also used in RNNs\n",
    "input_size = np.prod(conv_input_size) #np.prod(conv_input_size) #X_Train.shape[1] - len(ColumnsToBeDropped)\n",
    "output_size = K\n",
    "doFlatten = False #To NOT use conv, and flatten the image to begin with\n",
    "if doFlatten:\n",
    "    D = input_size\n",
    "print(\"conv_input_size: \" + str(conv_input_size) + \", input_size: \" + str(input_size) + \", D: \" + str(D) + \", output_size: \" + str(output_size))\n",
    "print(\"doFlatten=\", doFlatten)\n",
    "\n",
    "if (UsingPretrainedModel):\n",
    "    hn1 = D_after_pretrain\n",
    "elif H1 > 1 and W1 > 1 and D == 0:\n",
    "    hn1 = W1 #1 #It's a photo with no Colour layers and we Conv with it, not RNN which can't handle 4D tensors\n",
    "else:\n",
    "    hn1 = D if D > 0 else W1\n",
    "    \n",
    "EmbDim = None\n",
    "\n",
    "# layer_type = [\"dense\", \"dense\", \"dense\", \"dense\"] #\"dense\", \"rnn\", \"gru\", \"lstm\", \"conv\", \"stridedconv\", \"convpool\"\n",
    "num_layers = [1] #[1] #Only used for RNNs so far\n",
    "l2_lamda = 0.2\n",
    "mu = 0.9 #Momentum\n",
    "print()\n",
    "\n",
    "GDType = \"minibatch\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449f772d",
   "metadata": {},
   "source": [
    "## Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61da89c",
   "metadata": {},
   "source": [
    "### Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d236f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = np.array([])\n",
    "test_losses = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a109d054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Net(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=11025, out_features=6000, bias=False)\n",
      "    (1): ReLU6()\n",
      "    (2): BatchNorm1d(6000, eps=1e-05, momentum=0.7, affine=True, track_running_stats=True)\n",
      "    (3): Linear(in_features=6000, out_features=6000, bias=False)\n",
      "    (4): ReLU6()\n",
      "    (5): BatchNorm1d(6000, eps=1e-05, momentum=0.7, affine=True, track_running_stats=True)\n",
      "    (6): Linear(in_features=6000, out_features=6000, bias=False)\n",
      "    (7): ReLU6()\n",
      "    (8): BatchNorm1d(6000, eps=1e-05, momentum=0.7, affine=True, track_running_stats=True)\n",
      "    (9): Linear(in_features=6000, out_features=6000, bias=False)\n",
      "    (10): ReLU6()\n",
      "    (11): BatchNorm1d(6000, eps=1e-05, momentum=0.7, affine=True, track_running_stats=True)\n",
      "    (12): Linear(in_features=6000, out_features=600, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net(K, nEmbeddings = nEmbeddings).to(device)\n",
    "if (UsingPretrainedModel):\n",
    "    PretrainedModel.classifier = model.to(device)\n",
    "    model = PretrainedModel.to(device)\n",
    "print(device)\n",
    "print(model)\n",
    "\n",
    "train_losses = np.array([])\n",
    "test_losses = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d05aebff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_input_size: (11025,) \n",
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 6000]      66,150,000\n",
      "             ReLU6-2                 [-1, 6000]               0\n",
      "       BatchNorm1d-3                 [-1, 6000]          12,000\n",
      "            Linear-4                 [-1, 6000]      36,000,000\n",
      "             ReLU6-5                 [-1, 6000]               0\n",
      "       BatchNorm1d-6                 [-1, 6000]          12,000\n",
      "            Linear-7                 [-1, 6000]      36,000,000\n",
      "             ReLU6-8                 [-1, 6000]               0\n",
      "       BatchNorm1d-9                 [-1, 6000]          12,000\n",
      "           Linear-10                 [-1, 6000]      36,000,000\n",
      "            ReLU6-11                 [-1, 6000]               0\n",
      "      BatchNorm1d-12                 [-1, 6000]          12,000\n",
      "           Linear-13                  [-1, 600]       3,600,600\n",
      "================================================================\n",
      "Total params: 177,798,600\n",
      "Trainable params: 177,798,600\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 0.55\n",
      "Params size (MB): 678.25\n",
      "Estimated Total Size (MB): 678.84\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Debug = False\n",
    "print(\"conv_input_size:\", conv_input_size, \"\\n\")\n",
    "if not \"lstm\" in layer_type and SupervisedType != \"Recommender\": #LSTM don't work with summary #\"'tuple' object has no attribute 'size'\" error in torchsummary.py line 23\n",
    "    if ((any(item in [\"conv\", \"stridedconv\", \"convpool\"] for item in layer_type) or UsingPretrainedModel) and conv_input_size[0] == H1):\n",
    "        summary(model, tuple(conv_input_size[i] for i in [2, 0, 1]), device = str(device))\n",
    "    else:\n",
    "        summary(model, conv_input_size, device = str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89b12383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification\n"
     ]
    }
   ],
   "source": [
    "if (SupervisedType.lower() != \"gan\"):\n",
    "    if (SupervisedType.lower() == \"regression\" or SupervisedType.lower() == \"multivariateregression\") or SupervisedType.lower() == \"recommender\":\n",
    "        criterion = nn.MSELoss()\n",
    "        if SupervisedType.lower() == \"recommender\":\n",
    "            print(\"Recommender / MSELoss\")\n",
    "        elif SupervisedType.lower() == \"multivariateregression\":\n",
    "            print(\"Regression (Multivariate)\")\n",
    "        else:\n",
    "            print(\"Regression\")\n",
    "    elif (SupervisedType.lower() == \"classification\"):\n",
    "        if (K == 1):\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "            print(\"Binary Classification\")\n",
    "        else:\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            print(\"Multiclass Classification\")\n",
    "\n",
    "    learning_rate = 1e-4\n",
    "\n",
    "    #optimiser = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = mu, nesterov = False, weight_decay = l2_lamda) #LR=0.01\n",
    "    #Adam is fast, but tends to overfit\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr = learning_rate, betas = (mu, 0.999), weight_decay = l2_lamda) #LR=0.001 (0.9, 0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cc8fe8",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (NumPy Array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22b00ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batches: 256 batches_per_epoch: 27\n",
      "Epoch 1/50, Train Loss: 6.5336, Test Loss: 6.5652, Duration: 0:00:02.688969\n",
      "Epoch 2/50, Train Loss: 6.0872, Test Loss: 6.5115, Duration: 0:00:02.571449\n",
      "Epoch 3/50, Train Loss: 5.7630, Test Loss: 6.4840, Duration: 0:00:02.573449\n",
      "Epoch 4/50, Train Loss: 5.4873, Test Loss: 6.4081, Duration: 0:00:02.581451\n",
      "Epoch 5/50, Train Loss: 5.2507, Test Loss: 6.4367, Duration: 0:00:02.602457\n",
      "Epoch 6/50, Train Loss: 5.0590, Test Loss: 6.4254, Duration: 0:00:02.604956\n",
      "Epoch 7/50, Train Loss: 4.8995, Test Loss: 6.4641, Duration: 0:00:02.604954\n",
      "Epoch 8/50, Train Loss: 4.7721, Test Loss: 6.4340, Duration: 0:00:02.588452\n",
      "Epoch 9/50, Train Loss: 4.6640, Test Loss: 6.4078, Duration: 0:00:02.618457\n",
      "Epoch 10/50, Train Loss: 4.5784, Test Loss: 6.4246, Duration: 0:00:02.616457\n",
      "Epoch 11/50, Train Loss: 4.5131, Test Loss: 6.4039, Duration: 0:00:02.674967\n",
      "Epoch 12/50, Train Loss: 4.4582, Test Loss: 6.4083, Duration: 0:00:02.768483\n",
      "Epoch 13/50, Train Loss: 4.4204, Test Loss: 6.4062, Duration: 0:00:02.779485\n",
      "Epoch 14/50, Train Loss: 4.3878, Test Loss: 6.4208, Duration: 0:00:02.718474\n",
      "Epoch 15/50, Train Loss: 4.3613, Test Loss: 6.4210, Duration: 0:00:02.644461\n",
      "Epoch 16/50, Train Loss: 4.3431, Test Loss: 6.4204, Duration: 0:00:02.657463\n",
      "Epoch 17/50, Train Loss: 4.3303, Test Loss: 6.3965, Duration: 0:00:02.645461\n",
      "Epoch 18/50, Train Loss: 4.3294, Test Loss: 6.4065, Duration: 0:00:02.651463\n",
      "Epoch 19/50, Train Loss: 4.3229, Test Loss: 6.4133, Duration: 0:00:02.654463\n",
      "Epoch 20/50, Train Loss: 4.3229, Test Loss: 6.4154, Duration: 0:00:02.649462\n",
      "Epoch 21/50, Train Loss: 4.3254, Test Loss: 6.4004, Duration: 0:00:02.658965\n",
      "Epoch 22/50, Train Loss: 4.3303, Test Loss: 6.3945, Duration: 0:00:02.659465\n",
      "Epoch 23/50, Train Loss: 4.3349, Test Loss: 6.4388, Duration: 0:00:02.648462\n",
      "Epoch 24/50, Train Loss: 4.3415, Test Loss: 6.4200, Duration: 0:00:02.658965\n",
      "Epoch 25/50, Train Loss: 4.3468, Test Loss: 6.3870, Duration: 0:00:02.655463\n",
      "Epoch 26/50, Train Loss: 4.3570, Test Loss: 6.4178, Duration: 0:00:02.660464\n",
      "Epoch 27/50, Train Loss: 4.3654, Test Loss: 6.4147, Duration: 0:00:02.659966\n",
      "Epoch 28/50, Train Loss: 4.3718, Test Loss: 6.4058, Duration: 0:00:02.673466\n",
      "Epoch 29/50, Train Loss: 4.3808, Test Loss: 6.4092, Duration: 0:00:02.672465\n",
      "Epoch 30/50, Train Loss: 4.3911, Test Loss: 6.4069, Duration: 0:00:02.667466\n",
      "Epoch 31/50, Train Loss: 4.3991, Test Loss: 6.3824, Duration: 0:00:02.656465\n",
      "Epoch 32/50, Train Loss: 4.4135, Test Loss: 6.4133, Duration: 0:00:02.669966\n",
      "Epoch 33/50, Train Loss: 4.4228, Test Loss: 6.4269, Duration: 0:00:02.661465\n",
      "Epoch 34/50, Train Loss: 4.4330, Test Loss: 6.4137, Duration: 0:00:02.659464\n",
      "Epoch 35/50, Train Loss: 4.4450, Test Loss: 6.4253, Duration: 0:00:02.660964\n",
      "Epoch 36/50, Train Loss: 4.4543, Test Loss: 6.4294, Duration: 0:00:02.662964\n",
      "Epoch 37/50, Train Loss: 4.4623, Test Loss: 6.4046, Duration: 0:00:02.660965\n",
      "Epoch 38/50, Train Loss: 4.4744, Test Loss: 6.4137, Duration: 0:00:02.716992\n",
      "Epoch 39/50, Train Loss: 4.4843, Test Loss: 6.4138, Duration: 0:00:02.618458\n",
      "Epoch 40/50, Train Loss: 4.4929, Test Loss: 6.4064, Duration: 0:00:02.579951\n",
      "Epoch 41/50, Train Loss: 4.5027, Test Loss: 6.3924, Duration: 0:00:02.715473\n",
      "Epoch 42/50, Train Loss: 4.5127, Test Loss: 6.4198, Duration: 0:00:02.628459\n",
      "Epoch 43/50, Train Loss: 4.5224, Test Loss: 6.4171, Duration: 0:00:02.639960\n",
      "Epoch 44/50, Train Loss: 4.5336, Test Loss: 6.4221, Duration: 0:00:02.635960\n",
      "Epoch 45/50, Train Loss: 4.5436, Test Loss: 6.4241, Duration: 0:00:02.633460\n",
      "Epoch 46/50, Train Loss: 4.5557, Test Loss: 6.4204, Duration: 0:00:02.631958\n",
      "Epoch 47/50, Train Loss: 4.5644, Test Loss: 6.4227, Duration: 0:00:02.629959\n",
      "Epoch 48/50, Train Loss: 4.5761, Test Loss: 6.3962, Duration: 0:00:02.634960\n",
      "Epoch 49/50, Train Loss: 4.5861, Test Loss: 6.4064, Duration: 0:00:02.638960\n",
      "Epoch 50/50, Train Loss: 4.5987, Test Loss: 6.4186, Duration: 0:00:02.644462\n",
      "\n",
      "\n",
      "Done (Fri, 2021-05-14 23:42 EEST +0300) Elapsed time: 132.5 seconds\n"
     ]
    }
   ],
   "source": [
    "def minibatch_gd(model, criterion, optimiser, X_Train, Y_Train, X_Test, Y_Test, epochs, batch_size, ShufflePerIteration):\n",
    "    start_time = time.time()\n",
    "    model.to(device)\n",
    "    \n",
    "    if (H1 > 0 and W1 > 0 and D > 0):\n",
    "        X_Train = np.transpose(X_Train, (0, 3, 1, 2))\n",
    "        X_Test = np.transpose(X_Test, (0, 3, 1, 2))\n",
    "    \n",
    "    if (SupervisedType.lower() == \"recommender\"): #On Recommender, X_Train/X_Test are tuples, not NumPy Arrays\n",
    "        X_Train = list(X_Train)\n",
    "        X_Test = list(X_Test)\n",
    "        for i in range(len(X_Train)):\n",
    "            X_Train[i] = torch.from_numpy(X_Train[i]).long()\n",
    "            X_Test[i] = torch.from_numpy(X_Test[i]).long()\n",
    "    else:\n",
    "        X_Train = torch.from_numpy(X_Train).float()\n",
    "        X_Test = torch.from_numpy(X_Test).float()\n",
    "        \n",
    "    if (SupervisedType.lower() == \"recommender\" or SupervisedType.lower() == \"regression\" or SupervisedType.lower() == \"multivariateregression\") or (SupervisedType.lower() == \"classification\" and K == 1):\n",
    "        Y_Train = torch.from_numpy(Y_Train).float()\n",
    "        Y_Test = torch.from_numpy(Y_Test).float()\n",
    "    elif (SupervisedType.lower() == \"classification\"):\n",
    "        Y_Train = torch.from_numpy(Y_Train).long()\n",
    "        Y_Test = torch.from_numpy(Y_Test).long()\n",
    "    \n",
    "    train_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "    \n",
    "    batches_per_epoch = int(np.ceil(Y_Train.shape[0] / batch_size))\n",
    "    print(\"batches:\", batch_size, \"batches_per_epoch:\", batches_per_epoch)\n",
    "    \n",
    "    for it in range(epochs):\n",
    "        t0 = datetime.now()\n",
    "        \n",
    "        if (ShufflePerIteration):\n",
    "            RandIndx = np.arange(Y_Train.shape[0])\n",
    "            np.random.shuffle(RandIndx) #inplace function\n",
    "\n",
    "            if (SupervisedType.lower() == \"recommender\"):\n",
    "                X_Train = list(X_Train)\n",
    "                for i in range(len(X_Train)):\n",
    "                    X_Train[i] = X_Train[i][RandIndx]\n",
    "                X_Train = tuple(X_Train)\n",
    "            else:\n",
    "                X_Train = X_Train[RandIndx]\n",
    "            Y_Train = Y_Train[RandIndx]\n",
    "        elif (not ShufflePerIteration and SupervisedType.lower() == \"recommender\"):\n",
    "            X_Train = tuple(X_Train)\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for j in range(batches_per_epoch):\n",
    "            if SupervisedType.lower() == \"recommender\":\n",
    "                inputs = list()\n",
    "                for i in range(len(X_Train)):\n",
    "                    inputs.append(X_Train[i][j*batch_size:(j+1)*batch_size])\n",
    "                inputs = tuple(inputs)\n",
    "            else:\n",
    "                inputs = X_Train[j*batch_size:(j+1)*batch_size]\n",
    "            targets = Y_Train[j*batch_size:(j+1)*batch_size]\n",
    "            \n",
    "            if not SupervisedType.lower() == \"recommender\":\n",
    "                inputs = inputs.to(device) #Move data to GPU if GPU exists\n",
    "            targets = targets.to(device) #Move data to GPU if GPU exists\n",
    "            \n",
    "            optimiser.zero_grad() #Initialisation for parameters is another method here?\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            if K == 1:\n",
    "                outputs = outputs.view(-1)\n",
    "            #print(outputs.dtype, Y_Train.dtype)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "            optimiser.step()\n",
    "        train_loss = np.mean(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = []\n",
    "        for j in range(int(np.ceil(Y_Test.shape[0] / batch_size))):\n",
    "            if SupervisedType.lower() == \"recommender\":\n",
    "                test_inputs = list()\n",
    "                for i in range(len(X_Test)):\n",
    "                    test_inputs.append(X_Test[i][j*batch_size:(j+1)*batch_size])\n",
    "                test_inputs = tuple(test_inputs)\n",
    "            else:\n",
    "                test_inputs = X_Test[j*batch_size:(j+1)*batch_size]\n",
    "            test_targets = Y_Test[j*batch_size:(j+1)*batch_size]\n",
    "            \n",
    "            if not SupervisedType.lower() == \"recommender\":\n",
    "                test_inputs = test_inputs.to(device) #Move data to GPU if GPU exists\n",
    "            test_targets = test_targets.to(device) #Move data to GPU if GPU exists\n",
    "            \n",
    "            test_outputs = model(test_inputs)\n",
    "            \n",
    "            if K == 1:\n",
    "                test_outputs = test_outputs.view(-1)\n",
    "            \n",
    "            test_loss = criterion(test_outputs, test_targets).item()\n",
    "        test_loss = np.mean(test_loss)\n",
    "        \n",
    "        #Save the loss\n",
    "        train_losses[it] = train_loss\n",
    "        test_losses[it] = test_loss\n",
    "        \n",
    "        if (it + 1) % 1 == 0:\n",
    "            dt = datetime.now() - t0\n",
    "            print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Duration: {dt}')\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    FinishedOn = datetime.now(timezone('Europe/Athens')).strftime(\"%a, %Y-%m-%d %H:%M %Z %z\")\n",
    "    print(\"\\n\\nDone (\" + FinishedOn + \") Elapsed time: \" + str(round(elapsed_time, 1)) + \" seconds\")\n",
    "    return train_losses, test_losses\n",
    "\n",
    "GDType = \"minibatch\"\n",
    "Debug = False\n",
    "new_train_losses, new_test_losses = minibatch_gd(model, criterion, optimiser, X_Train, Y_Train, X_Test, Y_Test, epochs = 50, batch_size = batch_size, ShufflePerIteration = True)\n",
    "train_losses = np.append(train_losses, new_train_losses)\n",
    "test_losses = np.append(test_losses, new_test_losses)\n",
    "train_loss = train_losses[-1]\n",
    "test_loss = test_losses[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40afc0f8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Stochastic Gradient Descent (Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e8d224",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def batch_gd(model, criterion, optimiser, train_loader, test_loader, epochs):\n",
    "    start_time = time.time()\n",
    "    model.to(device)\n",
    "    \n",
    "    train_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "    for it in range(epochs):\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "        \n",
    "        model.train()\n",
    "        for inputs, targets in train_loader:\n",
    "            if (D == 0 and H1 > 0 and W1 > 0):\n",
    "                inputs = inputs.view(-1, H1, W1) #Probably an image of shape NxH1xW1x1, so let's delete the useless dimension\n",
    "            if (EmbDim is None):\n",
    "                inputs = inputs.float()\n",
    "            if (SupervisedType.lower() == \"recommender\" or SupervisedType.lower() == \"regression\" or SupervisedType.lower() == \"multivariateregression\") or (SupervisedType.lower() == \"classification\" and K == 1):\n",
    "                targets = targets.float()\n",
    "            elif (SupervisedType.lower() == \"classification\"):\n",
    "                targets = targets.long()\n",
    "                \n",
    "            if not SupervisedType.lower() == \"recommender\":\n",
    "                inputs = inputs.to(device) #Move data to GPU if GPU exists\n",
    "            targets = targets.to(device) #Move data to GPU if GPU exists\n",
    "            \n",
    "            optimiser.zero_grad() #Initialisation for parameters is another method here?\n",
    "\n",
    "#             print(\"inputs.shape:\", inputs.shape)\n",
    "            outputs = model(inputs)\n",
    "            if K == 1:\n",
    "                outputs = outputs.view(-1)\n",
    "            \n",
    "#             print(\"outputs.shape:\", outputs.shape, \"targets.shape:\", targets.shape)\n",
    "#             print(\"Unique targets:\", len(torch.unique(targets)), \"\\n\\n\", torch.unique(targets))\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "            optimiser.step()\n",
    "            print(f'Epoch {it+1}/{epochs}, Train Loss: {loss.item():.4f}')\n",
    "        train_loss = np.mean(train_loss) #Alternatively we could add all Iteration Losses instead of 1 Epoch loss, but the array length will be higher than Validation's\n",
    "        \n",
    "        test_loss = []\n",
    "        model.eval()\n",
    "        for inputs, targets in test_loader:\n",
    "            if (D == 0 and H1 > 0 and W1 > 0):\n",
    "                inputs = inputs.view(-1, H1, W1) #Probably an image of shape NxH1xW1x1, so let's delete the useless dimension\n",
    "            if (EmbDim is None):\n",
    "                inputs = inputs.float()\n",
    "            if (SupervisedType.lower() == \"regression\" or SupervisedType.lower() == \"multivariateregression\") or (SupervisedType.lower() == \"classification\" and K == 1):\n",
    "                targets = targets.float()\n",
    "            elif (SupervisedType.lower() == \"classification\"):\n",
    "                targets = targets.long()\n",
    "                \n",
    "            if not SupervisedType.lower() == \"recommender\":\n",
    "                inputs = inputs.to(device) #Move data to GPU if GPU exists\n",
    "            targets = targets.to(device) #Move data to GPU if GPU exists\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            if K == 1:\n",
    "                outputs = outputs.view(-1)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss.append(loss.item())\n",
    "        test_loss = np.mean(test_loss)\n",
    "        \n",
    "        train_losses[it] = train_loss\n",
    "        test_losses[it] = test_loss\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Duration: {dt}')\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    FinishedOn = datetime.now(timezone('Europe/Athens')).strftime(\"%a, %Y-%m-%d %H:%M %Z %z\")\n",
    "    print(\"Done (\" + FinishedOn + \") Elapsed time: \" + str(round(elapsed_time, 1)) + \" seconds\")\n",
    "    return train_losses, test_losses\n",
    "\n",
    "GDType = \"stochastic\"\n",
    "Debug = False\n",
    "new_train_losses, new_test_losses = batch_gd(model, criterion, optimiser, train_loader, test_loader, epochs = 1)\n",
    "train_losses = np.append(train_losses, new_train_losses)\n",
    "test_losses = np.append(test_losses, new_test_losses)\n",
    "train_loss = train_losses[-1]\n",
    "test_loss = test_losses[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5192afc7",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdc6ed3",
   "metadata": {},
   "source": [
    "## Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a16d598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label = \"Train Loss\")\n",
    "plt.plot(test_losses, label = \"Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac738594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch (NumPy)\n",
      "Test Iterations: 12\n",
      "Test ~N: 3072\n",
      "\n",
      "Train loss: 4.599. Train Acc: 99.97%.\n",
      " Test loss: 6.392.  Test Acc: 1.11%.  Class Weighted F1 Score: 0.56%\n"
     ]
    }
   ],
   "source": [
    "#Full Gradient Descent\n",
    "model.eval()\n",
    "if not \"train_losses\" in locals() and not \"train_losses\" in globals():\n",
    "    train_losses = [-np.Inf]\n",
    "with torch.no_grad():\n",
    "    if GDType == \"full\":\n",
    "        print(\"Full Gradient Descent\")        \n",
    "    elif GDType == \"stochastic\":\n",
    "        print(\"Stochastic GD\")\n",
    "        Actual_Y = np.array([])\n",
    "        Test_Actual_Y = np.array([])\n",
    "        #Stochastic Gradient Descent #Tested with Flatenned MNIST\n",
    "        model.to(device)\n",
    "\n",
    "        n_correct = 0.\n",
    "        n_total = 0.\n",
    "        for inputs, targets in train_loader:\n",
    "            if (D == 0 and H1 > 0 and W1 > 0):\n",
    "                inputs = inputs.view(-1, H1, W1) #Probably an image of shape NxH1xW1x1, so let's delete the useless dimension\n",
    "            inputs = inputs.float()\n",
    "            if (SupervisedType.lower() == \"regression\" or SupervisedType.lower() == \"multivariateregression\") or (SupervisedType.lower() == \"classification\" and K == 1):\n",
    "                targets = targets.float()\n",
    "            elif (SupervisedType.lower() == \"classification\"):\n",
    "                targets = targets.long()\n",
    "            inputs, targets = inputs.to(device), targets.to(device) #Move data to GPU if GPU exists\n",
    "\n",
    "            #inputs = inputs.view(-1, D) #Reshape the input if needed\n",
    "            #inputs = inputs.view(-1, train_dataset.data.shape[1], train_dataset.data.shape[2]) #Reshape the X_Train batch if needed\n",
    "\n",
    "            Actual_Y = np.append(Actual_Y, targets.cpu().numpy().astype(np.int32), axis = 0)\n",
    "            outputs = model(inputs) #Forward pass\n",
    "            if K == 1:\n",
    "                outputs = outputs.view(-1)\n",
    "            elif (SupervisedType.lower() == \"classification\"): #which means K>1 also\n",
    "                _, outputs = torch.max(outputs, 1) #Prediction. torch.max returns both max (value) and argmax (index)\n",
    "\n",
    "            # update counts\n",
    "            n_correct += (outputs == targets).sum().item() #.item() = One-element tensor -> Python scalar\n",
    "            n_total += targets.shape[0]\n",
    "        train_Acc = n_correct / n_total\n",
    "        \n",
    "        \n",
    "        n_correct = 0.\n",
    "        n_total = 0.\n",
    "        test_loss = []\n",
    "        if (SupervisedType.lower() == \"classification\" and K > 1):\n",
    "            Pred = np.array([], dtype = np.int64)\n",
    "            PredProb = []\n",
    "        else:\n",
    "            Pred = np.array([])\n",
    "\n",
    "        for inputs, targets in test_loader:\n",
    "            if (D == 0 and H1 > 0 and W1 > 0):\n",
    "                inputs = inputs.view(-1, H1, W1) #Probably an image of shape NxH1xW1x1, so let's delete the useless dimension\n",
    "            inputs = inputs.float()\n",
    "            if (SupervisedType.lower() == \"regression\" or SupervisedType.lower() == \"multivariateregression\") or (SupervisedType.lower() == \"classification\" and K == 1):\n",
    "                targets = targets.float()\n",
    "            elif (SupervisedType.lower() == \"classification\"):\n",
    "                targets = targets.long()\n",
    "            inputs, targets = inputs.to(device), targets.to(device) #Move data to GPU if GPU exists\n",
    "\n",
    "            #inputs = inputs.view(-1, test_dataset.data.shape[1], test_dataset.data.shape[2]) #Reshape the X_Train batch if needed\n",
    "            #inputs = inputs.view(-1, D) #Reshape the input if needed\n",
    "\n",
    "            Test_Actual_Y = np.append(Test_Actual_Y, targets.cpu().numpy().astype(np.int32), axis = 0)\n",
    "            outputs = model(inputs) #Forward pass\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss.append(loss.item())\n",
    "\n",
    "            if K == 1:\n",
    "                outputs = outputs.view(-1)\n",
    "            elif (SupervisedType.lower() == \"classification\"): #which means K>1 also\n",
    "                PredProb.extend(outputs.cpu().numpy())\n",
    "                _, outputs = torch.max(outputs, 1) #Prediction. torch.max returns both max (value) and argmax (index)\n",
    "\n",
    "            Pred = np.append(Pred, outputs.cpu().numpy())\n",
    "\n",
    "            # update counts\n",
    "            n_correct += (outputs == targets).sum().item()\n",
    "            n_total += targets.shape[0]\n",
    "\n",
    "\n",
    "        PredProb = np.array(PredProb)\n",
    "        #################################\n",
    "        ## Get the Losses to plot them ##\n",
    "        #################################\n",
    "        print(\"Test Iterations:\", len(test_loss))\n",
    "        print(\"Test ~N:\", (len(test_loss) * batch_size))\n",
    "        print()\n",
    "        test_loss = np.mean(test_loss)\n",
    "        test_Acc = n_correct / n_total\n",
    "        ClassWeightedF1 = f1_score(Test_Actual_Y, Pred, average = 'weighted')\n",
    "        \n",
    "        print('Train loss: {0:.3f}. Train Acc: {1:.2f}%.'.format(train_losses[-1], train_Acc * 100.))\n",
    "        print(' Test loss: {0:.3f}.  Test Acc: {1:.2f}%.  Class Weighted F1 Score: {2:.2f}%'.format(test_loss, test_Acc * 100., ClassWeightedF1 * 100.))\n",
    "        \n",
    "    elif GDType == \"minibatch\":\n",
    "        print(\"Minibatch (NumPy)\")\n",
    "        Actual_Y = np.array([])\n",
    "        Test_Actual_Y = np.array([])\n",
    "        Batches = int(np.ceil(Y_Train.shape[0] / batch_size))\n",
    "        \n",
    "        n_correct = 0.\n",
    "        n_total = 0.\n",
    "        for j in range(Batches):\n",
    "            inputs, targets = torch.from_numpy(X_Train[j*batch_size:(j+1)*batch_size]).float().to(device), torch.from_numpy(Y_Train[j*batch_size:(j+1)*batch_size]).float().to(device) #Move data to GPU if GPU exists\n",
    "            \n",
    "            if (H1 > 0 and W1 > 0 and D > 0): ### Not sure if it belongs here ###\n",
    "                inputs = inputs.permute(0, 3, 1, 2)\n",
    "                \n",
    "            if (D == 0 and H1 > 0 and W1 > 0):\n",
    "                inputs = inputs.view(-1, H1, W1) #Probably an image of shape NxH1xW1x1, so let's delete the useless dimension\n",
    "            inputs = inputs.float()\n",
    "            if (SupervisedType.lower() == \"regression\" or SupervisedType.lower() == \"multivariateregression\") or (SupervisedType.lower() == \"classification\" and K == 1):\n",
    "                targets = targets.float()\n",
    "            elif (SupervisedType.lower() == \"classification\"):\n",
    "                targets = targets.long()\n",
    "            inputs, targets = inputs.to(device), targets.to(device) #Move data to GPU if GPU exists\n",
    "\n",
    "            #inputs = inputs.view(-1, D) #Reshape the input if needed\n",
    "            #inputs = inputs.view(-1, train_dataset.data.shape[1], train_dataset.data.shape[2]) #Reshape the X_Train batch if needed\n",
    "                        \n",
    "            Actual_Y = np.append(Actual_Y, targets.cpu().numpy().astype(np.int32), axis = 0)\n",
    "            outputs = model(inputs) #Forward pass\n",
    "            if K == 1:\n",
    "                outputs = outputs.view(-1)\n",
    "            elif (SupervisedType.lower() == \"classification\"): #which means K>1 also\n",
    "                _, outputs = torch.max(outputs, 1) #Prediction. torch.max returns both max (value) and argmax (index)\n",
    "                \n",
    "            # update counts\n",
    "            n_correct += (outputs == targets).sum().item() #.item() = One-element tensor -> Python scalar\n",
    "            n_total += targets.shape[0]\n",
    "        train_Acc = n_correct / n_total\n",
    "        \n",
    "        \n",
    "        n_correct = 0.\n",
    "        n_total = 0.\n",
    "        test_loss = []\n",
    "        if (SupervisedType.lower() == \"classification\" and K > 1):\n",
    "            Pred = np.array([], dtype = np.int64)\n",
    "            PredProb = []\n",
    "        else:\n",
    "            Pred = np.array([])                \n",
    "              \n",
    "        for j in range(int(np.ceil(Y_Test.shape[0] / batch_size))):\n",
    "            inputs, targets = torch.from_numpy(X_Test[j*batch_size:(j+1)*batch_size]).float().to(device), torch.from_numpy(Y_Test[j*batch_size:(j+1)*batch_size]).float().to(device) #Move data to GPU if GPU exists\n",
    "            \n",
    "            if (H1 > 0 and W1 > 0 and D > 0): ### Not sure if it belongs here ###\n",
    "                inputs = inputs.permute(0, 3, 1, 2)\n",
    "                                \n",
    "            if (D == 0 and H1 > 0 and W1 > 0):\n",
    "                inputs = inputs.view(-1, H1, W1) #Probably an image of shape NxH1xW1x1, so let's delete the useless dimension\n",
    "            inputs = inputs.float()\n",
    "            if (SupervisedType.lower() == \"regression\" or SupervisedType.lower() == \"multivariateregression\") or (SupervisedType.lower() == \"classification\" and K == 1):\n",
    "                targets = targets.float()\n",
    "            elif (SupervisedType.lower() == \"classification\"):\n",
    "                targets = targets.long()\n",
    "            inputs, targets = inputs.to(device), targets.to(device) #Move data to GPU if GPU exists\n",
    "\n",
    "            #inputs = inputs.view(-1, test_dataset.data.shape[1], test_dataset.data.shape[2]) #Reshape the X_Train batch if needed\n",
    "            #inputs = inputs.view(-1, D) #Reshape the input if needed\n",
    "                \n",
    "            Test_Actual_Y = np.append(Test_Actual_Y, targets.cpu().numpy().astype(np.int32), axis = 0)\n",
    "            outputs = model(inputs) #Forward pass\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss.append(loss.item())\n",
    "\n",
    "            if K == 1:\n",
    "                outputs = outputs.view(-1)\n",
    "            elif (SupervisedType.lower() == \"classification\"): #which means K>1 also\n",
    "                PredProb.extend(outputs.cpu().numpy())\n",
    "                _, outputs = torch.max(outputs, 1) #Prediction. torch.max returns both max (value) and argmax (index)\n",
    "\n",
    "            Pred = np.append(Pred, outputs.cpu().numpy())\n",
    "\n",
    "            # update counts\n",
    "            n_correct += (outputs == targets).sum().item()\n",
    "            n_total += targets.shape[0]\n",
    "             \n",
    "            \n",
    "        PredProb = np.array(PredProb)   \n",
    "        #################################\n",
    "        ## Get the Losses to plot them ##\n",
    "        #################################\n",
    "        print(\"Test Iterations:\", len(test_loss))\n",
    "        print(\"Test ~N:\", (len(test_loss) * batch_size))\n",
    "        print()\n",
    "        test_loss = np.mean(test_loss)\n",
    "        test_Acc = n_correct / n_total\n",
    "        ClassWeightedF1 = f1_score(Y_Test, Pred, average = 'weighted')\n",
    "\n",
    "        print('Train loss: {0:.3f}. Train Acc: {1:.2f}%.'.format(train_losses[-1], train_Acc * 100.))\n",
    "        print(' Test loss: {0:.3f}.  Test Acc: {1:.2f}%.  Class Weighted F1 Score: {2:.2f}%'.format(test_loss, test_Acc * 100., ClassWeightedF1 * 100.))\n",
    "        \n",
    "    else:\n",
    "        print(\"Unknown Gradient Descent Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2b03205",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for each class (Along the Colums) for every recording (along the rows)\n",
      "\n",
      "Showing the probability of each class for recording No.1:\n",
      "\n",
      "[0.00153421 0.00186806 0.00145976 0.00119397 0.00194051 0.00141635\n",
      " 0.00181502 0.00148228 0.00201248 0.001576   0.00178205 0.00177723\n",
      " 0.00126594 0.00204753 0.00141108 0.0011684  0.00257951 0.00148369\n",
      " 0.001483   0.00143337 0.0013628  0.00184497 0.001425   0.00195158\n",
      " 0.00122875 0.00099888 0.00169307 0.00137151 0.001791   0.00143113\n",
      " 0.00188971 0.00176221 0.00141712 0.00159718 0.00225853 0.00198278\n",
      " 0.00155175 0.00198259 0.0015588  0.00158517 0.00176832 0.00133882\n",
      " 0.00144348 0.00165311 0.00217663 0.00201284 0.00175251 0.00137246\n",
      " 0.00201424 0.00190098 0.00202331 0.00132508 0.00165175 0.00135532\n",
      " 0.00183597 0.001812   0.00126223 0.00179291 0.00192687 0.00158856\n",
      " 0.00178972 0.00178039 0.00150229 0.00172223 0.00166127 0.00165096\n",
      " 0.00209191 0.00197046 0.0011826  0.00177211 0.00142478 0.00150412\n",
      " 0.00150417 0.00179181 0.00146136 0.00151434 0.00184502 0.00160527\n",
      " 0.00160522 0.0013021  0.00224215 0.00170138 0.00216676 0.00197131\n",
      " 0.0020819  0.00144411 0.00169464 0.00138978 0.00138435 0.00131783\n",
      " 0.00168228 0.00137976 0.00161733 0.00185508 0.00155982 0.00186987\n",
      " 0.00167544 0.00176394 0.00148805 0.00140122 0.00140729 0.00199746\n",
      " 0.001708   0.00153721 0.00149787 0.00144404 0.00174911 0.00180127\n",
      " 0.0017099  0.00134733 0.00166054 0.00146539 0.00168401 0.00171229\n",
      " 0.00132965 0.00156436 0.00191622 0.00182155 0.00174557 0.00128937\n",
      " 0.00149972 0.00193428 0.0017249  0.00153593 0.00168129 0.00127381\n",
      " 0.00181862 0.0022899  0.00165852 0.00180936 0.0015465  0.00127669\n",
      " 0.00167006 0.00208588 0.00132076 0.00239912 0.00112186 0.00203563\n",
      " 0.0016994  0.00126902 0.00174002 0.00140081 0.00172802 0.00146237\n",
      " 0.00162945 0.00134217 0.00215858 0.00153326 0.00104278 0.00177135\n",
      " 0.00193719 0.00212191 0.0025119  0.00199987 0.00122871 0.00142918\n",
      " 0.00156899 0.00148613 0.00213192 0.00139487 0.00173605 0.00173965\n",
      " 0.00183383 0.00178297 0.00174566 0.00159249 0.00218389 0.00180927\n",
      " 0.00241451 0.00148426 0.00151315 0.00101745 0.00175099 0.00156401\n",
      " 0.00165682 0.00178092 0.0014752  0.00162162 0.00147186 0.00190666\n",
      " 0.00189065 0.00151192 0.00178661 0.00180503 0.00214572 0.00126457\n",
      " 0.00167369 0.00153815 0.00177188 0.00191934 0.00187404 0.00139024\n",
      " 0.0017994  0.00131859 0.00124829 0.00149097 0.00162298 0.00163755\n",
      " 0.00199074 0.00196167 0.00135007 0.00174411 0.00171094 0.00139509\n",
      " 0.00146212 0.00232033 0.0015015  0.00142532 0.00149517 0.00105574\n",
      " 0.00152163 0.00201071 0.0015859  0.00114167 0.00193816 0.00166213\n",
      " 0.0018481  0.00140972 0.00132027 0.00142115 0.00157419 0.00164524\n",
      " 0.00190889 0.00133913 0.00155334 0.00156108 0.00172019 0.00157111\n",
      " 0.00146163 0.00184189 0.00176879 0.00156412 0.00139794 0.00174971\n",
      " 0.00148288 0.00141882 0.00180002 0.00191104 0.00130187 0.00170663\n",
      " 0.00177556 0.00210309 0.00211632 0.00142605 0.00180778 0.00173002\n",
      " 0.0014073  0.00131452 0.00178596 0.00138646 0.00160142 0.00173166\n",
      " 0.00196044 0.00184489 0.0018745  0.00167029 0.00142974 0.00164506\n",
      " 0.00191128 0.00154206 0.00140994 0.00173801 0.0015848  0.00148918\n",
      " 0.00182025 0.00176833 0.00149423 0.00193516 0.00150647 0.00152343\n",
      " 0.00188821 0.00163171 0.00153904 0.00181067 0.00186057 0.00187493\n",
      " 0.00155994 0.00127266 0.00224363 0.00120965 0.00166898 0.00175895\n",
      " 0.00163599 0.00127085 0.00186156 0.00179367 0.0019401  0.00144873\n",
      " 0.00152603 0.00181375 0.00137775 0.00173472 0.00162018 0.00167605\n",
      " 0.00224358 0.00141412 0.00193882 0.00177693 0.00173163 0.00174124\n",
      " 0.00177418 0.00185524 0.00186772 0.00210865 0.00129384 0.00170418\n",
      " 0.00156402 0.00139745 0.00127226 0.00157819 0.00193581 0.00207825\n",
      " 0.00158896 0.00231251 0.00175734 0.00150945 0.00179222 0.00164469\n",
      " 0.00147129 0.001488   0.001297   0.00191695 0.00189719 0.00183388\n",
      " 0.00089675 0.00159694 0.00170864 0.00200146 0.00137374 0.00190989\n",
      " 0.00204517 0.00160108 0.00155022 0.00169848 0.00176471 0.00227023\n",
      " 0.0013907  0.00198134 0.00167456 0.00109937 0.00126369 0.00141362\n",
      " 0.00146148 0.00144357 0.00135961 0.00140352 0.00147386 0.00153811\n",
      " 0.00175158 0.00141871 0.00137692 0.00165422 0.00152316 0.00224744\n",
      " 0.00141935 0.00151199 0.00136669 0.00147243 0.00152454 0.00170352\n",
      " 0.00130919 0.00169559 0.00162509 0.00179219 0.00187336 0.00153645\n",
      " 0.00197285 0.00163445 0.00161873 0.00147919 0.00189668 0.00204696\n",
      " 0.00175342 0.00134337 0.00172137 0.00140543 0.00160113 0.00135507\n",
      " 0.00185423 0.00265132 0.00167947 0.00185442 0.00181927 0.0018492\n",
      " 0.00195172 0.0015453  0.00161941 0.00160297 0.0017433  0.00142324\n",
      " 0.00136522 0.00146927 0.00160795 0.00158447 0.00140166 0.00167996\n",
      " 0.00148989 0.00137903 0.00205354 0.00149626 0.00187764 0.00167236\n",
      " 0.00197069 0.00149018 0.00148793 0.0020241  0.00174885 0.00196346\n",
      " 0.00195213 0.00156321 0.00251389 0.00120221 0.0015452  0.00157865\n",
      " 0.00123618 0.00173595 0.00192959 0.00189253 0.0015973  0.00220799\n",
      " 0.00170302 0.00132544 0.00149549 0.00196326 0.0027018  0.00187455\n",
      " 0.0016239  0.0018713  0.00138514 0.00174524 0.00184417 0.00226489\n",
      " 0.00162795 0.0012499  0.00137445 0.00181447 0.00168502 0.00188897\n",
      " 0.00149288 0.00165346 0.00120337 0.0015767  0.00177703 0.00159321\n",
      " 0.00218179 0.00199527 0.0018762  0.00149056 0.00125384 0.00176841\n",
      " 0.0013197  0.00172128 0.00186111 0.00161447 0.00121628 0.00178224\n",
      " 0.00164358 0.00169061 0.00202329 0.00159118 0.00163414 0.00210591\n",
      " 0.00155597 0.00167386 0.00127606 0.00115557 0.0019936  0.00198164\n",
      " 0.00166603 0.00188644 0.00137416 0.00139073 0.00185571 0.00157777\n",
      " 0.00172761 0.00179945 0.00170367 0.00178235 0.00132143 0.0018779\n",
      " 0.00188313 0.00175732 0.00156113 0.00155985 0.00167041 0.00168063\n",
      " 0.00258649 0.0015284  0.00141662 0.00217719 0.00140973 0.00155717\n",
      " 0.00220639 0.00184728 0.00147195 0.00185087 0.00171571 0.00203542\n",
      " 0.00214345 0.00184436 0.00214197 0.00130195 0.00160663 0.00155426\n",
      " 0.00124747 0.00171379 0.00160867 0.00119452 0.00258007 0.00147206\n",
      " 0.00152008 0.00160946 0.00188499 0.0019654  0.00199013 0.00171336\n",
      " 0.00145935 0.00205073 0.00208181 0.00158424 0.00186955 0.00183147\n",
      " 0.00151192 0.00128524 0.00197442 0.00122438 0.00161265 0.00161101\n",
      " 0.00144581 0.00152339 0.00133207 0.00148309 0.00128609 0.00211709\n",
      " 0.00141478 0.00176499 0.00175937 0.00152162 0.0014188  0.00182853\n",
      " 0.00183818 0.00161161 0.00165129 0.0017968  0.00183484 0.00129772\n",
      " 0.00124947 0.00176611 0.00118213 0.00133379 0.00219526 0.00163455\n",
      " 0.00208238 0.00157468 0.00125694 0.00148005 0.00163179 0.00218632\n",
      " 0.00164269 0.00144871 0.00168016 0.00174985 0.00187298 0.00136992\n",
      " 0.0016138  0.00182258 0.00183647 0.00156986 0.0025439  0.0015435\n",
      " 0.00183134 0.00161184 0.00160539 0.00143163 0.00163831 0.0017357\n",
      " 0.00138527 0.00152456 0.00140107 0.00184982 0.00143811 0.00172822\n",
      " 0.00178636 0.00174588 0.00166936 0.00161816 0.00166938 0.00128985\n",
      " 0.00171895 0.00144487 0.00189635 0.0018583  0.00159222 0.00184372\n",
      " 0.00192647 0.00122239 0.00168698 0.00177128 0.00138888 0.00151159]\n"
     ]
    }
   ],
   "source": [
    "print(\"Probabilities for each class (Along the Colums) for every recording (along the rows)\")\n",
    "\n",
    "RecordingNo = 1\n",
    "print(f\"\\nShowing the probability of each class for recording No.{RecordingNo}:\\n\")\n",
    "print(softmax(PredProb, axis = 1)[RecordingNo - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0298e8a9",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "158a7c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = test_losses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d499cf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorkingDir: D:\\GiannisM\\Downloads\\Exercises\\Fiver\\21. moozcast \n",
      "\n",
      "D:\\GiannisM\\Downloads\\Exercises\\Fiver\\21. moozcast/Models/2021-05-14 23-53, loss 6.42, Acc 0.01\n"
     ]
    }
   ],
   "source": [
    "# SaveFolderName = {}\n",
    "# for key in ModelParamsDict[CurModelNum]: SaveFolderName[key] = ModelParamsDict[CurModelNum][key]\n",
    "# for UnwantedKey in [\"EmbDim\", \"doFlatten\", \"bsize\", \"CFiltSz\", \"CMode\", \"CStride\", \"CPlSize\", \"CGlbMaxPl\", \"RMaxPl\"]: del SaveFolderName[UnwantedKey]\n",
    "\n",
    "WorkingDir = os.getcwd()\n",
    "print(\"WorkingDir:\", WorkingDir, \"\\n\")\n",
    "\n",
    "SaveFolder = (f\"{WorkingDir}/Models/\" +\n",
    "              datetime.now(timezone('Europe/Athens')).strftime(\"%Y-%m-%d %H-%M\") + \", \" +\n",
    "              \"loss \" + \"{0:.2f}\".format(test_loss) + \", \" +\n",
    "#               \"r2 \" + \"{0:.2f}\".format(test_r2)\n",
    "              \"Acc \" + \"{0:.2f}\".format(test_Acc) #+ \", \" +\n",
    "#               str(SaveFolderName).replace(\":\", \"=\").replace(\"'\", \"\").replace(\"{\", \"\").replace(\"}\", \"\")\n",
    ")\n",
    "print(SaveFolder)\n",
    "os.makedirs(SaveFolder, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd5d30a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad0f51b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i += 1\n",
    "print(i)\n",
    "_ih[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2db0bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PossibleNetClass = _ih[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aaac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving the Model ###\n",
    "\n",
    "#Saving the Parameters\n",
    "FileOptions = open(SaveFolder + \"/Parameters.py\", \"w\")\n",
    "FileOptions.writelines(f\"SupervisedType = '{SupervisedType}'\\ndoFlatten = {doFlatten}\\nDebug = False\\nGDType = '{GDType}'\")\n",
    "FileOptions.close() #to change file access modes\n",
    "\n",
    "#Saving the Optimiser\n",
    "FileOptions = open(SaveFolder + \"/Optimiser.txt\", \"w\")\n",
    "FileOptions.writelines(str(optimiser))\n",
    "FileOptions.close() #to change file access modes\n",
    "\n",
    "\n",
    "#Saving the Criterion\n",
    "with open(SaveFolder + \"/criterion.pt\", 'wb') as io:\n",
    "    pickle.dump(criterion, io)\n",
    "\n",
    "\n",
    "#Saving the Net() Class\n",
    "# pickle.dump(Net, SaveFolder + \"/Net.pt\")\n",
    "print(PossibleNetClass.partition('\\n')[0])\n",
    "with open(SaveFolder + \"/Net.py\", 'wb') as io:\n",
    "    #re.sub('[^a-zA-Z\\s]+', '', PossibleNetClass)\n",
    "    pickle.dump(PossibleNetClass, io)\n",
    "\n",
    "\n",
    "#Saving Model's Dictionary Only\n",
    "torch.save(model.state_dict(), SaveFolder + \"/model_dict.pt\")\n",
    "\n",
    "\n",
    "#Saving Model itself\n",
    "# torch.save(model, SaveFolder + \"/model.pt\")\n",
    "with open(SaveFolder + \"/model.pt\", 'wb') as io:\n",
    "    dill.dump(model, io)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca39f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the Model ###\n",
    "WorkingDir = os.getcwd()\n",
    "\n",
    "if not('SaveFolder' in locals() or 'SaveFolder' in globals()):\n",
    "    SaveFolder = fr\"{WorkingDir}\\Models\\2021-05-14 23-53, loss 6.42, Acc 0.01\"\n",
    "    print(f\"Using explicitly defined SaveFolder = {SaveFolder}\")\n",
    "\n",
    "\n",
    "#Loading the Parameters\n",
    "with open(SaveFolder + \"/Parameters.py\", \"r+\") as io:\n",
    "    exec(io.read())\n",
    "\n",
    "    \n",
    "#Loading the Criterion\n",
    "with open(SaveFolder + \"/criterion.pt\", \"rb\") as io:\n",
    "    criterion = pickle.load(io)\n",
    "\n",
    "\n",
    "#Loading the Net() Class\n",
    "with open(SaveFolder + \"/Net.py\", \"r+\") as io:\n",
    "#     exec(\"#\" + re.sub('[^a-zA-Z\\s():,.=\\']+', '', io.read()))\n",
    "    exec(\"#\" + RemLastLine(''.join(filter(lambda x: x in string.printable, io.read()))))\n",
    "#     exec(io.read())\n",
    "\n",
    "    \n",
    "#Loading Model itself\n",
    "with open(SaveFolder + \"/model.pt\", 'rb') as io:\n",
    "    model = dill.load(io)\n",
    "    \n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1704ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the Model ###\n",
    "WorkingDir = os.getcwd()\n",
    "\n",
    "if not('SaveFolder' in locals() or 'SaveFolder' in globals()):\n",
    "    SaveFolder = fr\"{WorkingDir}\\Models\\2021-05-14 23-53, loss 6.42, Acc 0.01\"\n",
    "    print(f\"Using explicitly defined SaveFolder = {SaveFolder}\")\n",
    "    \n",
    "model = Net(K, nEmbeddings = nEmbeddings).to(device)\n",
    "model.load_state_dict(torch.load(SaveFolder + \"/model_dict.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eba906",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cc183f2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11025,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28ec0dee",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\torch\\onnx\\symbolic_helper.py:680: UserWarning: ONNX export mode is set to inference mode, but operator batch_norm is set to inference mode. The model will be exported in inference, as specified by the export mode.\n",
      "  training_mode + \", as specified by the export mode.\")\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"1446pt\" height=\"216pt\"\r\n",
       " viewBox=\"0.00 0.00 1446.00 216.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(72 180)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"#ffffff\" stroke=\"none\" points=\"-72,36 -72,-180 1374,-180 1374,36 -72,36\"/>\r\n",
       "<!-- /outputs/27 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>/outputs/27</title>\r\n",
       "<polygon fill=\"#bcd6fc\" stroke=\"#7c96bc\" points=\"68,-144 0,-144 0,-108 68,-108 68,-144\"/>\r\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-123\" font-family=\"Verdana\" font-size=\"10.00\" fill=\"#202020\">Transpose</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/28 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>/outputs/28</title>\r\n",
       "<polygon fill=\"#bcd6fc\" stroke=\"#7c96bc\" points=\"158,-144 104,-144 104,-108 158,-108 158,-144\"/>\r\n",
       "<text text-anchor=\"start\" x=\"113\" y=\"-123\" font-family=\"Verdana\" font-size=\"10.00\" fill=\"#202020\">MatMul</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/27&#45;&gt;/outputs/28 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>/outputs/27&#45;&gt;/outputs/28</title>\r\n",
       "<path fill=\"none\" stroke=\"#7c96bc\" d=\"M68.2264,-126C76.4279,-126 85.2553,-126 93.5988,-126\"/>\r\n",
       "<polygon fill=\"#7c96bc\" stroke=\"#7c96bc\" points=\"93.8248,-129.5 103.825,-126 93.8247,-122.5 93.8248,-129.5\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/29 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>/outputs/29</title>\r\n",
       "<polygon fill=\"#bcd6fc\" stroke=\"#7c96bc\" points=\"248,-144 194,-144 194,-108 248,-108 248,-144\"/>\r\n",
       "<text text-anchor=\"start\" x=\"212\" y=\"-123\" font-family=\"Verdana\" font-size=\"10.00\" fill=\"#202020\">Clip</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/28&#45;&gt;/outputs/29 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>/outputs/28&#45;&gt;/outputs/29</title>\r\n",
       "<path fill=\"none\" stroke=\"#7c96bc\" d=\"M158.403,-126C166.393,-126 175.311,-126 183.824,-126\"/>\r\n",
       "<polygon fill=\"#7c96bc\" stroke=\"#7c96bc\" points=\"183.919,-129.5 193.919,-126 183.919,-122.5 183.919,-129.5\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/30 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>/outputs/30</title>\r\n",
       "<polygon fill=\"#bcd6fc\" stroke=\"#7c96bc\" points=\"354,-144 284,-144 284,-108 354,-108 354,-144\"/>\r\n",
       "<text text-anchor=\"start\" x=\"292\" y=\"-123\" font-family=\"Verdana\" font-size=\"10.00\" fill=\"#202020\">BatchNorm</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/29&#45;&gt;/outputs/30 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>/outputs/29&#45;&gt;/outputs/30</title>\r\n",
       "<path fill=\"none\" stroke=\"#7c96bc\" d=\"M248.232,-126C256.133,-126 265.032,-126 273.763,-126\"/>\r\n",
       "<polygon fill=\"#7c96bc\" stroke=\"#7c96bc\" points=\"273.867,-129.5 283.867,-126 273.867,-122.5 273.867,-129.5\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/32 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>/outputs/32</title>\r\n",
       "<polygon fill=\"#bcd6fc\" stroke=\"#7c96bc\" points=\"444,-117 390,-117 390,-81 444,-81 444,-117\"/>\r\n",
       "<text text-anchor=\"start\" x=\"399\" y=\"-96\" font-family=\"Verdana\" font-size=\"10.00\" fill=\"#202020\">MatMul</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/30&#45;&gt;/outputs/32 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>/outputs/30&#45;&gt;/outputs/32</title>\r\n",
       "<path fill=\"none\" stroke=\"#7c96bc\" d=\"M354.116,-116.405C362.561,-114.03 371.632,-111.478 380.156,-109.081\"/>\r\n",
       "<polygon fill=\"#7c96bc\" stroke=\"#7c96bc\" points=\"381.162,-112.434 389.841,-106.357 379.267,-105.695 381.162,-112.434\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/31 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>/outputs/31</title>\r\n",
       "<polygon fill=\"#bcd6fc\" stroke=\"#7c96bc\" points=\"353,-90 285,-90 285,-54 353,-54 353,-90\"/>\r\n",
       "<text text-anchor=\"start\" x=\"293\" y=\"-69\" font-family=\"Verdana\" font-size=\"10.00\" fill=\"#202020\">Transpose</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/31&#45;&gt;/outputs/32 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>/outputs/31&#45;&gt;/outputs/32</title>\r\n",
       "<path fill=\"none\" stroke=\"#7c96bc\" d=\"M353.038,-81.2919C361.786,-83.7523 371.271,-86.42 380.16,-88.9201\"/>\r\n",
       "<polygon fill=\"#7c96bc\" stroke=\"#7c96bc\" points=\"379.298,-92.3134 389.873,-91.6517 381.194,-85.5749 379.298,-92.3134\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/33 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>/outputs/33</title>\r\n",
       "<polygon fill=\"#bcd6fc\" stroke=\"#7c96bc\" points=\"534,-117 480,-117 480,-81 534,-81 534,-117\"/>\r\n",
       "<text text-anchor=\"start\" x=\"498\" y=\"-96\" font-family=\"Verdana\" font-size=\"10.00\" fill=\"#202020\">Clip</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/32&#45;&gt;/outputs/33 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>/outputs/32&#45;&gt;/outputs/33</title>\r\n",
       "<path fill=\"none\" stroke=\"#7c96bc\" d=\"M444.403,-99C452.393,-99 461.311,-99 469.824,-99\"/>\r\n",
       "<polygon fill=\"#7c96bc\" stroke=\"#7c96bc\" points=\"469.919,-102.5 479.919,-99 469.919,-95.5001 469.919,-102.5\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/34 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>/outputs/34</title>\r\n",
       "<polygon fill=\"#bcd6fc\" stroke=\"#7c96bc\" points=\"640,-117 570,-117 570,-81 640,-81 640,-117\"/>\r\n",
       "<text text-anchor=\"start\" x=\"578\" y=\"-96\" font-family=\"Verdana\" font-size=\"10.00\" fill=\"#202020\">BatchNorm</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/33&#45;&gt;/outputs/34 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>/outputs/33&#45;&gt;/outputs/34</title>\r\n",
       "<path fill=\"none\" stroke=\"#7c96bc\" d=\"M534.232,-99C542.133,-99 551.032,-99 559.763,-99\"/>\r\n",
       "<polygon fill=\"#7c96bc\" stroke=\"#7c96bc\" points=\"559.867,-102.5 569.867,-99 559.867,-95.5001 559.867,-102.5\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/36 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>/outputs/36</title>\r\n",
       "<polygon fill=\"#bcd6fc\" stroke=\"#7c96bc\" points=\"730,-90 676,-90 676,-54 730,-54 730,-90\"/>\r\n",
       "<text text-anchor=\"start\" x=\"685\" y=\"-69\" font-family=\"Verdana\" font-size=\"10.00\" fill=\"#202020\">MatMul</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/34&#45;&gt;/outputs/36 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>/outputs/34&#45;&gt;/outputs/36</title>\r\n",
       "<path fill=\"none\" stroke=\"#7c96bc\" d=\"M640.116,-89.4048C648.561,-87.0298 657.632,-84.4784 666.156,-82.081\"/>\r\n",
       "<polygon fill=\"#7c96bc\" stroke=\"#7c96bc\" points=\"667.162,-85.4341 675.841,-79.3572 665.267,-78.6955 667.162,-85.4341\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/35 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>/outputs/35</title>\r\n",
       "<polygon fill=\"#bcd6fc\" stroke=\"#7c96bc\" points=\"639,-63 571,-63 571,-27 639,-27 639,-63\"/>\r\n",
       "<text text-anchor=\"start\" x=\"579\" y=\"-42\" font-family=\"Verdana\" font-size=\"10.00\" fill=\"#202020\">Transpose</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/35&#45;&gt;/outputs/36 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>/outputs/35&#45;&gt;/outputs/36</title>\r\n",
       "<path fill=\"none\" stroke=\"#7c96bc\" d=\"M639.038,-54.2919C647.786,-56.7523 657.271,-59.42 666.16,-61.9201\"/>\r\n",
       "<polygon fill=\"#7c96bc\" stroke=\"#7c96bc\" points=\"665.298,-65.3134 675.873,-64.6517 667.194,-58.5749 665.298,-65.3134\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/37 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>/outputs/37</title>\r\n",
       "<polygon fill=\"#bcd6fc\" stroke=\"#7c96bc\" points=\"820,-90 766,-90 766,-54 820,-54 820,-90\"/>\r\n",
       "<text text-anchor=\"start\" x=\"784\" y=\"-69\" font-family=\"Verdana\" font-size=\"10.00\" fill=\"#202020\">Clip</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/36&#45;&gt;/outputs/37 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>/outputs/36&#45;&gt;/outputs/37</title>\r\n",
       "<path fill=\"none\" stroke=\"#7c96bc\" d=\"M730.403,-72C738.393,-72 747.311,-72 755.824,-72\"/>\r\n",
       "<polygon fill=\"#7c96bc\" stroke=\"#7c96bc\" points=\"755.919,-75.5001 765.919,-72 755.919,-68.5001 755.919,-75.5001\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/38 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>/outputs/38</title>\r\n",
       "<polygon fill=\"#bcd6fc\" stroke=\"#7c96bc\" points=\"926,-90 856,-90 856,-54 926,-54 926,-90\"/>\r\n",
       "<text text-anchor=\"start\" x=\"864\" y=\"-69\" font-family=\"Verdana\" font-size=\"10.00\" fill=\"#202020\">BatchNorm</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/37&#45;&gt;/outputs/38 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>/outputs/37&#45;&gt;/outputs/38</title>\r\n",
       "<path fill=\"none\" stroke=\"#7c96bc\" d=\"M820.232,-72C828.133,-72 837.032,-72 845.763,-72\"/>\r\n",
       "<polygon fill=\"#7c96bc\" stroke=\"#7c96bc\" points=\"845.867,-75.5001 855.867,-72 845.867,-68.5001 845.867,-75.5001\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/40 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>/outputs/40</title>\r\n",
       "<polygon fill=\"#bcd6fc\" stroke=\"#7c96bc\" points=\"1016,-63 962,-63 962,-27 1016,-27 1016,-63\"/>\r\n",
       "<text text-anchor=\"start\" x=\"971\" y=\"-42\" font-family=\"Verdana\" font-size=\"10.00\" fill=\"#202020\">MatMul</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/38&#45;&gt;/outputs/40 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>/outputs/38&#45;&gt;/outputs/40</title>\r\n",
       "<path fill=\"none\" stroke=\"#7c96bc\" d=\"M926.116,-62.4048C934.561,-60.0298 943.632,-57.4784 952.156,-55.081\"/>\r\n",
       "<polygon fill=\"#7c96bc\" stroke=\"#7c96bc\" points=\"953.162,-58.4341 961.841,-52.3572 951.267,-51.6955 953.162,-58.4341\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/39 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>/outputs/39</title>\r\n",
       "<polygon fill=\"#bcd6fc\" stroke=\"#7c96bc\" points=\"925,-36 857,-36 857,-0 925,-0 925,-36\"/>\r\n",
       "<text text-anchor=\"start\" x=\"865\" y=\"-15\" font-family=\"Verdana\" font-size=\"10.00\" fill=\"#202020\">Transpose</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/39&#45;&gt;/outputs/40 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>/outputs/39&#45;&gt;/outputs/40</title>\r\n",
       "<path fill=\"none\" stroke=\"#7c96bc\" d=\"M925.038,-27.2919C933.786,-29.7523 943.271,-32.42 952.16,-34.9201\"/>\r\n",
       "<polygon fill=\"#7c96bc\" stroke=\"#7c96bc\" points=\"951.298,-38.3134 961.873,-37.6517 953.194,-31.5749 951.298,-38.3134\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/41 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>/outputs/41</title>\r\n",
       "<polygon fill=\"#bcd6fc\" stroke=\"#7c96bc\" points=\"1106,-63 1052,-63 1052,-27 1106,-27 1106,-63\"/>\r\n",
       "<text text-anchor=\"start\" x=\"1070\" y=\"-42\" font-family=\"Verdana\" font-size=\"10.00\" fill=\"#202020\">Clip</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/40&#45;&gt;/outputs/41 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>/outputs/40&#45;&gt;/outputs/41</title>\r\n",
       "<path fill=\"none\" stroke=\"#7c96bc\" d=\"M1016.4,-45C1024.39,-45 1033.31,-45 1041.82,-45\"/>\r\n",
       "<polygon fill=\"#7c96bc\" stroke=\"#7c96bc\" points=\"1041.92,-48.5001 1051.92,-45 1041.92,-41.5001 1041.92,-48.5001\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/42 -->\r\n",
       "<g id=\"node16\" class=\"node\"><title>/outputs/42</title>\r\n",
       "<polygon fill=\"#bcd6fc\" stroke=\"#7c96bc\" points=\"1212,-63 1142,-63 1142,-27 1212,-27 1212,-63\"/>\r\n",
       "<text text-anchor=\"start\" x=\"1150\" y=\"-42\" font-family=\"Verdana\" font-size=\"10.00\" fill=\"#202020\">BatchNorm</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/41&#45;&gt;/outputs/42 -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>/outputs/41&#45;&gt;/outputs/42</title>\r\n",
       "<path fill=\"none\" stroke=\"#7c96bc\" d=\"M1106.23,-45C1114.13,-45 1123.03,-45 1131.76,-45\"/>\r\n",
       "<polygon fill=\"#7c96bc\" stroke=\"#7c96bc\" points=\"1131.87,-48.5001 1141.87,-45 1131.87,-41.5001 1131.87,-48.5001\"/>\r\n",
       "</g>\r\n",
       "<!-- /outputs/43 -->\r\n",
       "<g id=\"node17\" class=\"node\"><title>/outputs/43</title>\r\n",
       "<polygon fill=\"#bcd6fc\" stroke=\"#7c96bc\" points=\"1302,-63 1248,-63 1248,-27 1302,-27 1302,-63\"/>\r\n",
       "<text text-anchor=\"start\" x=\"1260\" y=\"-42\" font-family=\"Verdana\" font-size=\"10.00\" fill=\"#202020\">Linear</text>\r\n",
       "</g>\r\n",
       "<!-- /outputs/42&#45;&gt;/outputs/43 -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>/outputs/42&#45;&gt;/outputs/43</title>\r\n",
       "<path fill=\"none\" stroke=\"#7c96bc\" d=\"M1212.12,-45C1220.38,-45 1229.24,-45 1237.6,-45\"/>\r\n",
       "<polygon fill=\"#7c96bc\" stroke=\"#7c96bc\" points=\"1237.84,-48.5001 1247.84,-45 1237.84,-41.5001 1237.84,-48.5001\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<hiddenlayer.graph.Graph at 0x2441e82b788>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#conda install graphviz python-graphviz\n",
    "#pip install hiddenlayer\n",
    "import hiddenlayer as hl\n",
    "hl_graph = hl.build_graph(model, torch.zeros(list(tuple([1, conv_input_size[0]])), device = device), )\n",
    "hl_graph.theme = hl.graph.THEMES[\"blue\"].copy()\n",
    "hl_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe4b9172",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"1004pt\" height=\"858pt\"\r\n",
       " viewBox=\"0.00 0.00 1004.00 857.71\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.870772 0.870772) rotate(0) translate(4 981)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-981 1149,-981 1149,4 -4,4\"/>\r\n",
       "<!-- 2495971669240 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>2495971669240</title>\r\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"889,-31 800,-31 800,-0 889,-0 889,-31\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"844.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (2881, 600)</text>\r\n",
       "</g>\r\n",
       "<!-- 2495084100232 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>2495084100232</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"892,-86 797,-86 797,-67 892,-67 892,-86\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"844.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2495084100232&#45;&gt;2495971669240 -->\r\n",
       "<g id=\"edge46\" class=\"edge\"><title>2495084100232&#45;&gt;2495971669240</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M844.5,-66.7943C844.5,-60.0669 844.5,-50.404 844.5,-41.3425\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"848,-41.1932 844.5,-31.1933 841,-41.1933 848,-41.1932\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086125448 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2495086125448</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"696,-141 595,-141 595,-122 696,-122 696,-141\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"645.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086125448&#45;&gt;2495084100232 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>2495086125448&#45;&gt;2495084100232</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M677.473,-121.985C711.317,-112.971 764.896,-98.7012 802.212,-88.7625\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"803.514,-92.0379 812.277,-86.0821 801.713,-85.2737 803.514,-92.0379\"/>\r\n",
       "</g>\r\n",
       "<!-- 2494628609064 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>2494628609064</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"639,-207 538,-207 538,-177 639,-177 639,-207\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"588.5\" y=\"-195\" font-family=\"monospace\" font-size=\"10.00\">layers.12.bias</text>\r\n",
       "<text text-anchor=\"middle\" x=\"588.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\"> (600)</text>\r\n",
       "</g>\r\n",
       "<!-- 2494628609064&#45;&gt;2495086125448 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>2494628609064&#45;&gt;2495086125448</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M602.298,-176.839C610.572,-168.347 621.123,-157.519 629.726,-148.689\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"632.487,-150.871 636.959,-141.266 627.473,-145.986 632.487,-150.871\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086125704 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>2495086125704</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"919,-141 770,-141 770,-122 919,-122 919,-141\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"844.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">CudnnBatchNormBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086125704&#45;&gt;2495084100232 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2495086125704&#45;&gt;2495084100232</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M844.5,-121.748C844.5,-114.802 844.5,-104.845 844.5,-96.1349\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"848,-96.089 844.5,-86.089 841,-96.0891 848,-96.089\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086125640 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>2495086125640</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"776,-201.5 657,-201.5 657,-182.5 776,-182.5 776,-201.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"716.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">HardtanhBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086125640&#45;&gt;2495086125704 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>2495086125640&#45;&gt;2495086125704</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M735.112,-182.494C756.536,-172.702 791.941,-156.521 816.649,-145.229\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"818.225,-148.357 825.865,-141.017 815.315,-141.99 818.225,-148.357\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086097224 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>2495086097224</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"755,-267.5 678,-267.5 678,-248.5 755,-248.5 755,-267.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"716.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\">MmBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086097224&#45;&gt;2495086125640 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>2495086097224&#45;&gt;2495086125640</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M716.5,-248.369C716.5,-239.164 716.5,-224.287 716.5,-212.271\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"720,-211.905 716.5,-201.905 713,-211.905 720,-211.905\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086097032 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>2495086097032</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"727,-328 578,-328 578,-309 727,-309 727,-328\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"652.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\">CudnnBatchNormBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086097032&#45;&gt;2495086097224 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>2495086097032&#45;&gt;2495086097224</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M661.943,-308.868C671.775,-299.882 687.386,-285.612 699.395,-274.635\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"701.998,-276.998 707.018,-267.667 697.275,-271.831 701.998,-276.998\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086097608 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>2495086097608</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"557,-383 438,-383 438,-364 557,-364 557,-383\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"497.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">HardtanhBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086097608&#45;&gt;2495086097032 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>2495086097608&#45;&gt;2495086097032</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M522.403,-363.985C548.201,-355.164 588.72,-341.309 617.682,-331.405\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"619.072,-334.629 627.401,-328.082 616.807,-328.006 619.072,-334.629\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086097928 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>2495086097928</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"536,-443.5 459,-443.5 459,-424.5 536,-424.5 536,-443.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"497.5\" y=\"-431.5\" font-family=\"monospace\" font-size=\"10.00\">MmBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086097928&#45;&gt;2495086097608 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>2495086097928&#45;&gt;2495086097608</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M497.5,-424.368C497.5,-416.246 497.5,-403.807 497.5,-393.385\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"501,-393.167 497.5,-383.167 494,-393.167 501,-393.167\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086098056 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>2495086098056</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"508,-504 359,-504 359,-485 508,-485 508,-504\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"433.5\" y=\"-492\" font-family=\"monospace\" font-size=\"10.00\">CudnnBatchNormBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086098056&#45;&gt;2495086097928 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>2495086098056&#45;&gt;2495086097928</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M442.943,-484.868C452.775,-475.882 468.386,-461.612 480.395,-450.635\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"482.998,-452.998 488.018,-443.667 478.275,-447.831 482.998,-452.998\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086098376 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>2495086098376</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"338,-559 219,-559 219,-540 338,-540 338,-559\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"278.5\" y=\"-547\" font-family=\"monospace\" font-size=\"10.00\">HardtanhBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086098376&#45;&gt;2495086098056 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>2495086098376&#45;&gt;2495086098056</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M303.403,-539.985C329.201,-531.164 369.72,-517.309 398.682,-507.405\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"400.072,-510.629 408.401,-504.082 397.807,-504.006 400.072,-510.629\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086098632 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>2495086098632</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"317,-619.5 240,-619.5 240,-600.5 317,-600.5 317,-619.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"278.5\" y=\"-607.5\" font-family=\"monospace\" font-size=\"10.00\">MmBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086098632&#45;&gt;2495086098376 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>2495086098632&#45;&gt;2495086098376</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M278.5,-600.368C278.5,-592.246 278.5,-579.807 278.5,-569.385\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"282,-569.167 278.5,-559.167 275,-569.167 282,-569.167\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086098120 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>2495086098120</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"289,-680 140,-680 140,-661 289,-661 289,-680\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"214.5\" y=\"-668\" font-family=\"monospace\" font-size=\"10.00\">CudnnBatchNormBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086098120&#45;&gt;2495086098632 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>2495086098120&#45;&gt;2495086098632</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M223.943,-660.868C233.775,-651.882 249.386,-637.612 261.395,-626.635\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"263.998,-628.998 269.018,-619.667 259.275,-623.831 263.998,-628.998\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086098952 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>2495086098952</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"119,-735 -7.10543e-015,-735 -7.10543e-015,-716 119,-716 119,-735\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"59.5\" y=\"-723\" font-family=\"monospace\" font-size=\"10.00\">HardtanhBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086098952&#45;&gt;2495086098120 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>2495086098952&#45;&gt;2495086098120</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M84.4034,-715.985C110.201,-707.164 150.72,-693.309 179.682,-683.405\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"181.072,-686.629 189.401,-680.082 178.807,-680.006 181.072,-686.629\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086099272 -->\r\n",
       "<g id=\"node16\" class=\"node\"><title>2495086099272</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"98,-795.5 21,-795.5 21,-776.5 98,-776.5 98,-795.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"59.5\" y=\"-783.5\" font-family=\"monospace\" font-size=\"10.00\">MmBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086099272&#45;&gt;2495086098952 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>2495086099272&#45;&gt;2495086098952</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.5,-776.368C59.5,-768.246 59.5,-755.807 59.5,-745.385\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"63.0001,-745.167 59.5,-735.167 56.0001,-745.167 63.0001,-745.167\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086099400 -->\r\n",
       "<g id=\"node17\" class=\"node\"><title>2495086099400</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-856 24,-856 24,-837 95,-837 95,-856\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"59.5\" y=\"-844\" font-family=\"monospace\" font-size=\"10.00\">TBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086099400&#45;&gt;2495086099272 -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>2495086099400&#45;&gt;2495086099272</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.5,-836.868C59.5,-828.746 59.5,-816.307 59.5,-805.885\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"63.0001,-805.667 59.5,-795.667 56.0001,-805.667 63.0001,-805.667\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086099528 -->\r\n",
       "<g id=\"node18\" class=\"node\"><title>2495086099528</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"110,-911 9,-911 9,-892 110,-892 110,-911\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"59.5\" y=\"-899\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086099528&#45;&gt;2495086099400 -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>2495086099528&#45;&gt;2495086099400</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.5,-891.748C59.5,-884.802 59.5,-874.845 59.5,-866.135\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"63.0001,-866.089 59.5,-856.089 56.0001,-866.089 63.0001,-866.089\"/>\r\n",
       "</g>\r\n",
       "<!-- 2491592713144 -->\r\n",
       "<g id=\"node19\" class=\"node\"><title>2491592713144</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"113,-977 6,-977 6,-947 113,-947 113,-977\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"59.5\" y=\"-965\" font-family=\"monospace\" font-size=\"10.00\">layers.0.weight</text>\r\n",
       "<text text-anchor=\"middle\" x=\"59.5\" y=\"-954\" font-family=\"monospace\" font-size=\"10.00\"> (6000, 11025)</text>\r\n",
       "</g>\r\n",
       "<!-- 2491592713144&#45;&gt;2495086099528 -->\r\n",
       "<g id=\"edge17\" class=\"edge\"><title>2491592713144&#45;&gt;2495086099528</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.5,-946.839C59.5,-939.214 59.5,-929.704 59.5,-921.45\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"63.0001,-921.266 59.5,-911.266 56.0001,-921.266 63.0001,-921.266\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086099016 -->\r\n",
       "<g id=\"node20\" class=\"node\"><title>2495086099016</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"238,-735 137,-735 137,-716 238,-716 238,-735\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-723\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086099016&#45;&gt;2495086098120 -->\r\n",
       "<g id=\"edge18\" class=\"edge\"><title>2495086099016&#45;&gt;2495086098120</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M191.959,-715.748C195.615,-708.571 200.909,-698.178 205.448,-689.268\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"208.704,-690.588 210.124,-680.089 202.467,-687.411 208.704,-690.588\"/>\r\n",
       "</g>\r\n",
       "<!-- 2491592474520 -->\r\n",
       "<g id=\"node21\" class=\"node\"><title>2491592474520</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"241,-801 134,-801 134,-771 241,-771 241,-801\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-789\" font-family=\"monospace\" font-size=\"10.00\">layers.2.weight</text>\r\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-778\" font-family=\"monospace\" font-size=\"10.00\"> (6000)</text>\r\n",
       "</g>\r\n",
       "<!-- 2491592474520&#45;&gt;2495086099016 -->\r\n",
       "<g id=\"edge19\" class=\"edge\"><title>2491592474520&#45;&gt;2495086099016</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M187.5,-770.839C187.5,-763.214 187.5,-753.704 187.5,-745.45\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"191,-745.266 187.5,-735.266 184,-745.266 191,-745.266\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086099080 -->\r\n",
       "<g id=\"node22\" class=\"node\"><title>2495086099080</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"357,-735 256,-735 256,-716 357,-716 357,-735\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"306.5\" y=\"-723\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086099080&#45;&gt;2495086098120 -->\r\n",
       "<g id=\"edge20\" class=\"edge\"><title>2495086099080&#45;&gt;2495086098120</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M291.719,-715.985C277.319,-707.689 255.191,-694.941 238.308,-685.215\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"239.962,-682.129 229.55,-680.17 236.468,-688.195 239.962,-682.129\"/>\r\n",
       "</g>\r\n",
       "<!-- 2491592713944 -->\r\n",
       "<g id=\"node23\" class=\"node\"><title>2491592713944</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"354,-801 259,-801 259,-771 354,-771 354,-801\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"306.5\" y=\"-789\" font-family=\"monospace\" font-size=\"10.00\">layers.2.bias</text>\r\n",
       "<text text-anchor=\"middle\" x=\"306.5\" y=\"-778\" font-family=\"monospace\" font-size=\"10.00\"> (6000)</text>\r\n",
       "</g>\r\n",
       "<!-- 2491592713944&#45;&gt;2495086099080 -->\r\n",
       "<g id=\"edge21\" class=\"edge\"><title>2491592713944&#45;&gt;2495086099080</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M306.5,-770.839C306.5,-763.214 306.5,-753.704 306.5,-745.45\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"310,-745.266 306.5,-735.266 303,-745.266 310,-745.266\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086098760 -->\r\n",
       "<g id=\"node24\" class=\"node\"><title>2495086098760</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"433,-680 362,-680 362,-661 433,-661 433,-680\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"397.5\" y=\"-668\" font-family=\"monospace\" font-size=\"10.00\">TBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086098760&#45;&gt;2495086098632 -->\r\n",
       "<g id=\"edge22\" class=\"edge\"><title>2495086098760&#45;&gt;2495086098632</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M380.196,-660.994C360.455,-651.289 327.945,-635.307 305.005,-624.03\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"306.343,-620.787 295.825,-619.517 303.255,-627.069 306.343,-620.787\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086099144 -->\r\n",
       "<g id=\"node25\" class=\"node\"><title>2495086099144</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"476,-735 375,-735 375,-716 476,-716 476,-735\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"425.5\" y=\"-723\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086099144&#45;&gt;2495086098760 -->\r\n",
       "<g id=\"edge23\" class=\"edge\"><title>2495086099144&#45;&gt;2495086098760</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M420.876,-715.748C417.044,-708.493 411.476,-697.954 406.735,-688.981\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"409.804,-687.296 402.038,-680.089 403.614,-690.566 409.804,-687.296\"/>\r\n",
       "</g>\r\n",
       "<!-- 2491592715544 -->\r\n",
       "<g id=\"node26\" class=\"node\"><title>2491592715544</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"479,-801 372,-801 372,-771 479,-771 479,-801\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"425.5\" y=\"-789\" font-family=\"monospace\" font-size=\"10.00\">layers.3.weight</text>\r\n",
       "<text text-anchor=\"middle\" x=\"425.5\" y=\"-778\" font-family=\"monospace\" font-size=\"10.00\"> (6000, 6000)</text>\r\n",
       "</g>\r\n",
       "<!-- 2491592715544&#45;&gt;2495086099144 -->\r\n",
       "<g id=\"edge24\" class=\"edge\"><title>2491592715544&#45;&gt;2495086099144</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M425.5,-770.839C425.5,-763.214 425.5,-753.704 425.5,-745.45\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"429,-745.266 425.5,-735.266 422,-745.266 429,-745.266\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086098440 -->\r\n",
       "<g id=\"node27\" class=\"node\"><title>2495086098440</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"457,-559 356,-559 356,-540 457,-540 457,-559\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"406.5\" y=\"-547\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086098440&#45;&gt;2495086098056 -->\r\n",
       "<g id=\"edge25\" class=\"edge\"><title>2495086098440&#45;&gt;2495086098056</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M410.959,-539.748C414.615,-532.571 419.909,-522.178 424.448,-513.268\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"427.704,-514.588 429.124,-504.089 421.467,-511.411 427.704,-514.588\"/>\r\n",
       "</g>\r\n",
       "<!-- 2491592714984 -->\r\n",
       "<g id=\"node28\" class=\"node\"><title>2491592714984</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"460,-625 353,-625 353,-595 460,-595 460,-625\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"406.5\" y=\"-613\" font-family=\"monospace\" font-size=\"10.00\">layers.5.weight</text>\r\n",
       "<text text-anchor=\"middle\" x=\"406.5\" y=\"-602\" font-family=\"monospace\" font-size=\"10.00\"> (6000)</text>\r\n",
       "</g>\r\n",
       "<!-- 2491592714984&#45;&gt;2495086098440 -->\r\n",
       "<g id=\"edge26\" class=\"edge\"><title>2491592714984&#45;&gt;2495086098440</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M406.5,-594.839C406.5,-587.214 406.5,-577.704 406.5,-569.45\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"410,-569.266 406.5,-559.266 403,-569.266 410,-569.266\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086098504 -->\r\n",
       "<g id=\"node29\" class=\"node\"><title>2495086098504</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"576,-559 475,-559 475,-540 576,-540 576,-559\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"525.5\" y=\"-547\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086098504&#45;&gt;2495086098056 -->\r\n",
       "<g id=\"edge27\" class=\"edge\"><title>2495086098504&#45;&gt;2495086098056</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M510.719,-539.985C496.319,-531.689 474.191,-518.941 457.308,-509.215\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"458.962,-506.129 448.55,-504.17 455.468,-512.195 458.962,-506.129\"/>\r\n",
       "</g>\r\n",
       "<!-- 2491592714824 -->\r\n",
       "<g id=\"node30\" class=\"node\"><title>2491592714824</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"573,-625 478,-625 478,-595 573,-595 573,-625\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"525.5\" y=\"-613\" font-family=\"monospace\" font-size=\"10.00\">layers.5.bias</text>\r\n",
       "<text text-anchor=\"middle\" x=\"525.5\" y=\"-602\" font-family=\"monospace\" font-size=\"10.00\"> (6000)</text>\r\n",
       "</g>\r\n",
       "<!-- 2491592714824&#45;&gt;2495086098504 -->\r\n",
       "<g id=\"edge28\" class=\"edge\"><title>2491592714824&#45;&gt;2495086098504</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M525.5,-594.839C525.5,-587.214 525.5,-577.704 525.5,-569.45\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"529,-569.266 525.5,-559.266 522,-569.266 529,-569.266\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086098184 -->\r\n",
       "<g id=\"node31\" class=\"node\"><title>2495086098184</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"652,-504 581,-504 581,-485 652,-485 652,-504\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"616.5\" y=\"-492\" font-family=\"monospace\" font-size=\"10.00\">TBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086098184&#45;&gt;2495086097928 -->\r\n",
       "<g id=\"edge29\" class=\"edge\"><title>2495086098184&#45;&gt;2495086097928</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M599.196,-484.994C579.455,-475.289 546.945,-459.307 524.005,-448.03\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"525.343,-444.787 514.825,-443.517 522.255,-451.069 525.343,-444.787\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086098568 -->\r\n",
       "<g id=\"node32\" class=\"node\"><title>2495086098568</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"695,-559 594,-559 594,-540 695,-540 695,-559\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"644.5\" y=\"-547\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086098568&#45;&gt;2495086098184 -->\r\n",
       "<g id=\"edge30\" class=\"edge\"><title>2495086098568&#45;&gt;2495086098184</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M639.876,-539.748C636.044,-532.493 630.476,-521.954 625.735,-512.981\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"628.804,-511.296 621.038,-504.089 622.614,-514.566 628.804,-511.296\"/>\r\n",
       "</g>\r\n",
       "<!-- 2491592714504 -->\r\n",
       "<g id=\"node33\" class=\"node\"><title>2491592714504</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"698,-625 591,-625 591,-595 698,-595 698,-625\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"644.5\" y=\"-613\" font-family=\"monospace\" font-size=\"10.00\">layers.6.weight</text>\r\n",
       "<text text-anchor=\"middle\" x=\"644.5\" y=\"-602\" font-family=\"monospace\" font-size=\"10.00\"> (6000, 6000)</text>\r\n",
       "</g>\r\n",
       "<!-- 2491592714504&#45;&gt;2495086098568 -->\r\n",
       "<g id=\"edge31\" class=\"edge\"><title>2491592714504&#45;&gt;2495086098568</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M644.5,-594.839C644.5,-587.214 644.5,-577.704 644.5,-569.45\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"648,-569.266 644.5,-559.266 641,-569.266 648,-569.266\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086097672 -->\r\n",
       "<g id=\"node34\" class=\"node\"><title>2495086097672</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"676,-383 575,-383 575,-364 676,-364 676,-383\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"625.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086097672&#45;&gt;2495086097032 -->\r\n",
       "<g id=\"edge32\" class=\"edge\"><title>2495086097672&#45;&gt;2495086097032</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M629.959,-363.748C633.615,-356.571 638.909,-346.178 643.448,-337.268\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"646.704,-338.588 648.124,-328.089 640.467,-335.411 646.704,-338.588\"/>\r\n",
       "</g>\r\n",
       "<!-- 2491592712344 -->\r\n",
       "<g id=\"node35\" class=\"node\"><title>2491592712344</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"679,-449 572,-449 572,-419 679,-419 679,-449\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"625.5\" y=\"-437\" font-family=\"monospace\" font-size=\"10.00\">layers.8.weight</text>\r\n",
       "<text text-anchor=\"middle\" x=\"625.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\"> (6000)</text>\r\n",
       "</g>\r\n",
       "<!-- 2491592712344&#45;&gt;2495086097672 -->\r\n",
       "<g id=\"edge33\" class=\"edge\"><title>2491592712344&#45;&gt;2495086097672</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M625.5,-418.839C625.5,-411.214 625.5,-401.704 625.5,-393.45\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"629,-393.266 625.5,-383.266 622,-393.266 629,-393.266\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086097736 -->\r\n",
       "<g id=\"node36\" class=\"node\"><title>2495086097736</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"795,-383 694,-383 694,-364 795,-364 795,-383\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"744.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086097736&#45;&gt;2495086097032 -->\r\n",
       "<g id=\"edge34\" class=\"edge\"><title>2495086097736&#45;&gt;2495086097032</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M729.719,-363.985C715.319,-355.689 693.191,-342.941 676.308,-333.215\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"677.962,-330.129 667.55,-328.17 674.468,-336.195 677.962,-330.129\"/>\r\n",
       "</g>\r\n",
       "<!-- 2491592714424 -->\r\n",
       "<g id=\"node37\" class=\"node\"><title>2491592714424</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"792,-449 697,-449 697,-419 792,-419 792,-449\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"744.5\" y=\"-437\" font-family=\"monospace\" font-size=\"10.00\">layers.8.bias</text>\r\n",
       "<text text-anchor=\"middle\" x=\"744.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\"> (6000)</text>\r\n",
       "</g>\r\n",
       "<!-- 2491592714424&#45;&gt;2495086097736 -->\r\n",
       "<g id=\"edge35\" class=\"edge\"><title>2491592714424&#45;&gt;2495086097736</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M744.5,-418.839C744.5,-411.214 744.5,-401.704 744.5,-393.45\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"748,-393.266 744.5,-383.266 741,-393.266 748,-393.266\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086097416 -->\r\n",
       "<g id=\"node38\" class=\"node\"><title>2495086097416</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"871,-328 800,-328 800,-309 871,-309 871,-328\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"835.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\">TBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086097416&#45;&gt;2495086097224 -->\r\n",
       "<g id=\"edge36\" class=\"edge\"><title>2495086097416&#45;&gt;2495086097224</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M818.196,-308.994C798.455,-299.289 765.945,-283.307 743.005,-272.03\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"744.343,-268.787 733.825,-267.517 741.255,-275.069 744.343,-268.787\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086097800 -->\r\n",
       "<g id=\"node39\" class=\"node\"><title>2495086097800</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"914,-383 813,-383 813,-364 914,-364 914,-383\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"863.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086097800&#45;&gt;2495086097416 -->\r\n",
       "<g id=\"edge37\" class=\"edge\"><title>2495086097800&#45;&gt;2495086097416</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M858.876,-363.748C855.044,-356.493 849.476,-345.954 844.735,-336.981\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"847.804,-335.296 840.038,-328.089 841.614,-338.566 847.804,-335.296\"/>\r\n",
       "</g>\r\n",
       "<!-- 2491592864536 -->\r\n",
       "<g id=\"node40\" class=\"node\"><title>2491592864536</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"917,-449 810,-449 810,-419 917,-419 917,-449\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"863.5\" y=\"-437\" font-family=\"monospace\" font-size=\"10.00\">layers.9.weight</text>\r\n",
       "<text text-anchor=\"middle\" x=\"863.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\"> (6000, 6000)</text>\r\n",
       "</g>\r\n",
       "<!-- 2491592864536&#45;&gt;2495086097800 -->\r\n",
       "<g id=\"edge38\" class=\"edge\"><title>2491592864536&#45;&gt;2495086097800</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M863.5,-418.839C863.5,-411.214 863.5,-401.704 863.5,-393.45\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"867,-393.266 863.5,-383.266 860,-393.266 867,-393.266\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086096968 -->\r\n",
       "<g id=\"node41\" class=\"node\"><title>2495086096968</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"895,-201.5 794,-201.5 794,-182.5 895,-182.5 895,-201.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"844.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086096968&#45;&gt;2495086125704 -->\r\n",
       "<g id=\"edge39\" class=\"edge\"><title>2495086096968&#45;&gt;2495086125704</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M844.5,-182.368C844.5,-174.246 844.5,-161.807 844.5,-151.385\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"848,-151.167 844.5,-141.167 841,-151.167 848,-151.167\"/>\r\n",
       "</g>\r\n",
       "<!-- 2494628609384 -->\r\n",
       "<g id=\"node42\" class=\"node\"><title>2494628609384</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"895,-273 782,-273 782,-243 895,-243 895,-273\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"838.5\" y=\"-261\" font-family=\"monospace\" font-size=\"10.00\">layers.11.weight</text>\r\n",
       "<text text-anchor=\"middle\" x=\"838.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\"> (6000)</text>\r\n",
       "</g>\r\n",
       "<!-- 2494628609384&#45;&gt;2495086096968 -->\r\n",
       "<g id=\"edge40\" class=\"edge\"><title>2494628609384&#45;&gt;2495086096968</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M839.832,-242.796C840.684,-233.699 841.801,-221.788 842.728,-211.897\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"846.222,-212.127 843.671,-201.844 839.253,-211.474 846.222,-212.127\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086097096 -->\r\n",
       "<g id=\"node43\" class=\"node\"><title>2495086097096</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1014,-201.5 913,-201.5 913,-182.5 1014,-182.5 1014,-201.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"963.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086097096&#45;&gt;2495086125704 -->\r\n",
       "<g id=\"edge41\" class=\"edge\"><title>2495086097096&#45;&gt;2495086125704</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M946.196,-182.494C926.455,-172.789 893.945,-156.807 871.005,-145.53\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"872.343,-142.287 861.825,-141.017 869.255,-148.569 872.343,-142.287\"/>\r\n",
       "</g>\r\n",
       "<!-- 2494628607144 -->\r\n",
       "<g id=\"node44\" class=\"node\"><title>2494628607144</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"1014,-273 913,-273 913,-243 1014,-243 1014,-273\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"963.5\" y=\"-261\" font-family=\"monospace\" font-size=\"10.00\">layers.11.bias</text>\r\n",
       "<text text-anchor=\"middle\" x=\"963.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\"> (6000)</text>\r\n",
       "</g>\r\n",
       "<!-- 2494628607144&#45;&gt;2495086097096 -->\r\n",
       "<g id=\"edge42\" class=\"edge\"><title>2494628607144&#45;&gt;2495086097096</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M963.5,-242.796C963.5,-233.699 963.5,-221.788 963.5,-211.897\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"967,-211.844 963.5,-201.844 960,-211.844 967,-211.844\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086096904 -->\r\n",
       "<g id=\"node45\" class=\"node\"><title>2495086096904</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1064,-141 993,-141 993,-122 1064,-122 1064,-141\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1028.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">TBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086096904&#45;&gt;2495084100232 -->\r\n",
       "<g id=\"edge43\" class=\"edge\"><title>2495086096904&#45;&gt;2495084100232</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M998.937,-121.985C967.778,-113.009 918.527,-98.823 884.043,-88.8902\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"884.873,-85.4868 874.294,-86.0821 882.935,-92.2133 884.873,-85.4868\"/>\r\n",
       "</g>\r\n",
       "<!-- 2495086097160 -->\r\n",
       "<g id=\"node46\" class=\"node\"><title>2495086097160</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1136,-201.5 1035,-201.5 1035,-182.5 1136,-182.5 1136,-201.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1085.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\r\n",
       "</g>\r\n",
       "<!-- 2495086097160&#45;&gt;2495086096904 -->\r\n",
       "<g id=\"edge44\" class=\"edge\"><title>2495086097160&#45;&gt;2495086096904</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1077.09,-182.368C1068.42,-173.468 1054.7,-159.386 1044.04,-148.453\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1046.43,-145.887 1036.95,-141.167 1041.42,-150.772 1046.43,-145.887\"/>\r\n",
       "</g>\r\n",
       "<!-- 2494628607624 -->\r\n",
       "<g id=\"node47\" class=\"node\"><title>2494628607624</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"1145,-273 1032,-273 1032,-243 1145,-243 1145,-273\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1088.5\" y=\"-261\" font-family=\"monospace\" font-size=\"10.00\">layers.12.weight</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1088.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\"> (600, 6000)</text>\r\n",
       "</g>\r\n",
       "<!-- 2494628607624&#45;&gt;2495086097160 -->\r\n",
       "<g id=\"edge45\" class=\"edge\"><title>2494628607624&#45;&gt;2495086097160</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1087.83,-242.796C1087.41,-233.699 1086.85,-221.788 1086.39,-211.897\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1089.88,-211.669 1085.91,-201.844 1082.89,-211.997 1089.88,-211.669\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x244eeb87188>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pip install torchviz\n",
    "from torchviz import make_dot\n",
    "make_dot(model(torch.from_numpy(X_Test).to(device)), params = dict(list(model.named_parameters())), show_attrs = False, show_saved = False)#.render(\"NN\", format = \"png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
